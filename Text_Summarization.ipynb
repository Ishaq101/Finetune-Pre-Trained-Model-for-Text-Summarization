{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hv-9Ma0b1kE3"
      },
      "source": [
        "## Get Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRaw19yJzUe4"
      },
      "source": [
        "### Install Package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6jLhuJpSTXl2",
        "outputId": "5fff1e79-b02b-4273-be04-22e8279610ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.32.1-py3-none-any.whl (314 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.32.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install -U accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RFjsFswzDy5M",
        "outputId": "a1954a8f-633c-4d37-8992-b1ec446908c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ACJeGEY0Y4ve",
        "outputId": "02192eef-b02c-4ac8-f1fc-847cb67c7a12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.25.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.23.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.15.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "x1qmQqNnY7vQ",
        "outputId": "d89afaaa-03db-4789-977a-021c84740916"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.25.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oZsDWhJbKZP3",
        "outputId": "61c72820-7aec-4089-e72d-6df030532eaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                          Version\n",
            "-------------------------------- ---------------------\n",
            "absl-py                          1.4.0\n",
            "accelerate                       0.32.1\n",
            "aiohttp                          3.9.5\n",
            "aiosignal                        1.3.1\n",
            "alabaster                        0.7.16\n",
            "albumentations                   1.3.1\n",
            "altair                           4.2.2\n",
            "annotated-types                  0.7.0\n",
            "anyio                            3.7.1\n",
            "argon2-cffi                      23.1.0\n",
            "argon2-cffi-bindings             21.2.0\n",
            "array_record                     0.5.1\n",
            "arviz                            0.15.1\n",
            "astropy                          5.3.4\n",
            "astunparse                       1.6.3\n",
            "async-timeout                    4.0.3\n",
            "atpublic                         4.1.0\n",
            "attrs                            23.2.0\n",
            "audioread                        3.0.1\n",
            "autograd                         1.6.2\n",
            "Babel                            2.15.0\n",
            "backcall                         0.2.0\n",
            "beautifulsoup4                   4.12.3\n",
            "bidict                           0.23.1\n",
            "bigframes                        1.11.1\n",
            "bleach                           6.1.0\n",
            "blinker                          1.4\n",
            "blis                             0.7.11\n",
            "blosc2                           2.0.0\n",
            "bokeh                            3.3.4\n",
            "bqplot                           0.12.43\n",
            "branca                           0.7.2\n",
            "build                            1.2.1\n",
            "CacheControl                     0.14.0\n",
            "cachetools                       5.3.3\n",
            "catalogue                        2.0.10\n",
            "certifi                          2024.7.4\n",
            "cffi                             1.16.0\n",
            "chardet                          5.2.0\n",
            "charset-normalizer               3.3.2\n",
            "chex                             0.1.86\n",
            "click                            8.1.7\n",
            "click-plugins                    1.1.1\n",
            "cligj                            0.7.2\n",
            "cloudpathlib                     0.18.1\n",
            "cloudpickle                      2.2.1\n",
            "cmake                            3.27.9\n",
            "cmdstanpy                        1.2.4\n",
            "colorcet                         3.1.0\n",
            "colorlover                       0.3.0\n",
            "colour                           0.1.5\n",
            "community                        1.0.0b1\n",
            "confection                       0.1.5\n",
            "cons                             0.4.6\n",
            "contextlib2                      21.6.0\n",
            "contourpy                        1.2.1\n",
            "cryptography                     42.0.8\n",
            "cuda-python                      12.2.1\n",
            "cudf-cu12                        24.4.1\n",
            "cufflinks                        0.17.3\n",
            "cupy-cuda12x                     12.2.0\n",
            "cvxopt                           1.3.2\n",
            "cvxpy                            1.3.4\n",
            "cycler                           0.12.1\n",
            "cymem                            2.0.8\n",
            "Cython                           3.0.10\n",
            "dask                             2023.8.1\n",
            "datascience                      0.17.6\n",
            "datasets                         2.20.0\n",
            "db-dtypes                        1.2.0\n",
            "dbus-python                      1.2.18\n",
            "debugpy                          1.6.6\n",
            "decorator                        4.4.2\n",
            "defusedxml                       0.7.1\n",
            "dill                             0.3.8\n",
            "distributed                      2023.8.1\n",
            "distro                           1.7.0\n",
            "dlib                             19.24.4\n",
            "dm-tree                          0.1.8\n",
            "docstring_parser                 0.16\n",
            "docutils                         0.18.1\n",
            "dopamine_rl                      4.0.9\n",
            "duckdb                           0.10.3\n",
            "earthengine-api                  0.1.411\n",
            "easydict                         1.13\n",
            "ecos                             2.0.14\n",
            "editdistance                     0.6.2\n",
            "eerepr                           0.0.4\n",
            "en-core-web-sm                   3.7.1\n",
            "entrypoints                      0.4\n",
            "et-xmlfile                       1.1.0\n",
            "etils                            1.7.0\n",
            "etuples                          0.3.9\n",
            "evaluate                         0.4.2\n",
            "exceptiongroup                   1.2.2\n",
            "fastai                           2.7.15\n",
            "fastcore                         1.5.54\n",
            "fastdownload                     0.0.7\n",
            "fastjsonschema                   2.20.0\n",
            "fastprogress                     1.0.3\n",
            "fastrlock                        0.8.2\n",
            "filelock                         3.15.4\n",
            "fiona                            1.9.6\n",
            "firebase-admin                   5.3.0\n",
            "Flask                            2.2.5\n",
            "flatbuffers                      24.3.25\n",
            "flax                             0.8.4\n",
            "folium                           0.14.0\n",
            "fonttools                        4.53.1\n",
            "frozendict                       2.4.4\n",
            "frozenlist                       1.4.1\n",
            "fsspec                           2023.6.0\n",
            "future                           0.18.3\n",
            "gast                             0.6.0\n",
            "gcsfs                            2023.6.0\n",
            "GDAL                             3.6.4\n",
            "gdown                            5.1.0\n",
            "geemap                           0.33.0\n",
            "gensim                           4.3.2\n",
            "geocoder                         1.38.1\n",
            "geographiclib                    2.0\n",
            "geopandas                        0.13.2\n",
            "geopy                            2.3.0\n",
            "gin-config                       0.5.0\n",
            "glob2                            0.7\n",
            "google                           2.0.3\n",
            "google-ai-generativelanguage     0.6.4\n",
            "google-api-core                  2.16.2\n",
            "google-api-python-client         2.84.0\n",
            "google-auth                      2.27.0\n",
            "google-auth-httplib2             0.1.1\n",
            "google-auth-oauthlib             1.2.1\n",
            "google-cloud-aiplatform          1.59.0\n",
            "google-cloud-bigquery            3.21.0\n",
            "google-cloud-bigquery-connection 1.12.1\n",
            "google-cloud-bigquery-storage    2.25.0\n",
            "google-cloud-bigtable            2.24.0\n",
            "google-cloud-core                2.3.3\n",
            "google-cloud-datastore           2.15.2\n",
            "google-cloud-firestore           2.11.1\n",
            "google-cloud-functions           1.13.3\n",
            "google-cloud-iam                 2.15.1\n",
            "google-cloud-language            2.13.4\n",
            "google-cloud-pubsub              2.22.0\n",
            "google-cloud-resource-manager    1.12.4\n",
            "google-cloud-storage             2.8.0\n",
            "google-cloud-translate           3.11.3\n",
            "google-colab                     1.0.0\n",
            "google-crc32c                    1.5.0\n",
            "google-generativeai              0.5.4\n",
            "google-pasta                     0.2.0\n",
            "google-resumable-media           2.7.1\n",
            "googleapis-common-protos         1.63.2\n",
            "googledrivedownloader            0.4\n",
            "graphviz                         0.20.3\n",
            "greenlet                         3.0.3\n",
            "grpc-google-iam-v1               0.13.1\n",
            "grpcio                           1.64.1\n",
            "grpcio-status                    1.48.2\n",
            "gspread                          6.0.2\n",
            "gspread-dataframe                3.3.1\n",
            "gym                              0.25.2\n",
            "gym-notices                      0.0.8\n",
            "h5netcdf                         1.3.0\n",
            "h5py                             3.9.0\n",
            "holidays                         0.53\n",
            "holoviews                        1.17.1\n",
            "html5lib                         1.1\n",
            "httpimport                       1.3.1\n",
            "httplib2                         0.22.0\n",
            "huggingface-hub                  0.23.4\n",
            "humanize                         4.7.0\n",
            "hyperopt                         0.2.7\n",
            "ibis-framework                   8.0.0\n",
            "idna                             3.7\n",
            "imageio                          2.31.6\n",
            "imageio-ffmpeg                   0.5.1\n",
            "imagesize                        1.4.1\n",
            "imbalanced-learn                 0.10.1\n",
            "imgaug                           0.4.0\n",
            "immutabledict                    4.2.0\n",
            "importlib_metadata               8.0.0\n",
            "importlib_resources              6.4.0\n",
            "imutils                          0.5.4\n",
            "inflect                          7.0.0\n",
            "iniconfig                        2.0.0\n",
            "intel-openmp                     2023.2.4\n",
            "ipyevents                        2.0.2\n",
            "ipyfilechooser                   0.6.0\n",
            "ipykernel                        5.5.6\n",
            "ipyleaflet                       0.18.2\n",
            "ipyparallel                      8.8.0\n",
            "ipython                          7.34.0\n",
            "ipython-genutils                 0.2.0\n",
            "ipython-sql                      0.5.0\n",
            "ipytree                          0.2.2\n",
            "ipywidgets                       7.7.1\n",
            "itsdangerous                     2.2.0\n",
            "jax                              0.4.26\n",
            "jaxlib                           0.4.26+cuda12.cudnn89\n",
            "jeepney                          0.7.1\n",
            "jellyfish                        1.0.4\n",
            "jieba                            0.42.1\n",
            "Jinja2                           3.1.4\n",
            "joblib                           1.4.2\n",
            "jsonpickle                       3.2.2\n",
            "jsonschema                       4.19.2\n",
            "jsonschema-specifications        2023.12.1\n",
            "jupyter-client                   6.1.12\n",
            "jupyter-console                  6.1.0\n",
            "jupyter_core                     5.7.2\n",
            "jupyter-server                   1.24.0\n",
            "jupyterlab_pygments              0.3.0\n",
            "jupyterlab_widgets               3.0.11\n",
            "kaggle                           1.6.14\n",
            "kagglehub                        0.2.7\n",
            "keras                            2.15.0\n",
            "keyring                          23.5.0\n",
            "kiwisolver                       1.4.5\n",
            "langcodes                        3.4.0\n",
            "language_data                    1.2.0\n",
            "launchpadlib                     1.10.16\n",
            "lazr.restfulclient               0.14.4\n",
            "lazr.uri                         1.0.6\n",
            "lazy_loader                      0.4\n",
            "libclang                         18.1.1\n",
            "librosa                          0.10.2.post1\n",
            "lightgbm                         4.1.0\n",
            "linkify-it-py                    2.0.3\n",
            "llvmlite                         0.41.1\n",
            "locket                           1.0.0\n",
            "logical-unification              0.4.6\n",
            "lxml                             4.9.4\n",
            "malloy                           2023.1067\n",
            "marisa-trie                      1.2.0\n",
            "Markdown                         3.6\n",
            "markdown-it-py                   3.0.0\n",
            "MarkupSafe                       2.1.5\n",
            "matplotlib                       3.7.1\n",
            "matplotlib-inline                0.1.7\n",
            "matplotlib-venn                  0.11.10\n",
            "mdit-py-plugins                  0.4.1\n",
            "mdurl                            0.1.2\n",
            "miniKanren                       1.0.3\n",
            "missingno                        0.5.2\n",
            "mistune                          0.8.4\n",
            "mizani                           0.9.3\n",
            "mkl                              2023.2.0\n",
            "ml-dtypes                        0.2.0\n",
            "mlxtend                          0.22.0\n",
            "more-itertools                   10.1.0\n",
            "moviepy                          1.0.3\n",
            "mpmath                           1.3.0\n",
            "msgpack                          1.0.8\n",
            "multidict                        6.0.5\n",
            "multipledispatch                 1.0.0\n",
            "multiprocess                     0.70.16\n",
            "multitasking                     0.0.11\n",
            "murmurhash                       1.0.10\n",
            "music21                          9.1.0\n",
            "natsort                          8.4.0\n",
            "nbclassic                        1.1.0\n",
            "nbclient                         0.10.0\n",
            "nbconvert                        6.5.4\n",
            "nbformat                         5.10.4\n",
            "nest-asyncio                     1.6.0\n",
            "networkx                         3.3\n",
            "nibabel                          4.0.2\n",
            "nltk                             3.8.1\n",
            "notebook                         6.5.5\n",
            "notebook_shim                    0.2.4\n",
            "numba                            0.58.1\n",
            "numexpr                          2.10.1\n",
            "numpy                            1.25.2\n",
            "nvidia-cublas-cu12               12.1.3.1\n",
            "nvidia-cuda-cupti-cu12           12.1.105\n",
            "nvidia-cuda-nvrtc-cu12           12.1.105\n",
            "nvidia-cuda-runtime-cu12         12.1.105\n",
            "nvidia-cudnn-cu12                8.9.2.26\n",
            "nvidia-cufft-cu12                11.0.2.54\n",
            "nvidia-curand-cu12               10.3.2.106\n",
            "nvidia-cusolver-cu12             11.4.5.107\n",
            "nvidia-cusparse-cu12             12.1.0.106\n",
            "nvidia-nccl-cu12                 2.20.5\n",
            "nvidia-nvjitlink-cu12            12.5.82\n",
            "nvidia-nvtx-cu12                 12.1.105\n",
            "nvtx                             0.2.10\n",
            "oauth2client                     4.1.3\n",
            "oauthlib                         3.2.2\n",
            "opencv-contrib-python            4.8.0.76\n",
            "opencv-python                    4.8.0.76\n",
            "opencv-python-headless           4.10.0.84\n",
            "openpyxl                         3.1.5\n",
            "opt-einsum                       3.3.0\n",
            "optax                            0.2.2\n",
            "orbax-checkpoint                 0.4.4\n",
            "osqp                             0.6.2.post8\n",
            "packaging                        24.1\n",
            "pandas                           2.0.3\n",
            "pandas-datareader                0.10.0\n",
            "pandas-gbq                       0.19.2\n",
            "pandas-stubs                     2.0.3.230814\n",
            "pandocfilters                    1.5.1\n",
            "panel                            1.3.8\n",
            "param                            2.1.1\n",
            "parso                            0.8.4\n",
            "parsy                            2.1\n",
            "partd                            1.4.2\n",
            "pathlib                          1.0.1\n",
            "patsy                            0.5.6\n",
            "peewee                           3.17.6\n",
            "pexpect                          4.9.0\n",
            "pickleshare                      0.7.5\n",
            "Pillow                           9.4.0\n",
            "pip                              23.1.2\n",
            "pip-tools                        6.13.0\n",
            "platformdirs                     4.2.2\n",
            "plotly                           5.15.0\n",
            "plotnine                         0.12.4\n",
            "pluggy                           1.5.0\n",
            "polars                           0.20.2\n",
            "pooch                            1.8.2\n",
            "portpicker                       1.5.2\n",
            "prefetch-generator               1.0.3\n",
            "preshed                          3.0.9\n",
            "prettytable                      3.10.2\n",
            "proglog                          0.1.10\n",
            "progressbar2                     4.2.0\n",
            "prometheus_client                0.20.0\n",
            "promise                          2.3\n",
            "prompt_toolkit                   3.0.47\n",
            "prophet                          1.1.5\n",
            "proto-plus                       1.24.0\n",
            "protobuf                         3.20.3\n",
            "psutil                           5.9.5\n",
            "psycopg2                         2.9.9\n",
            "ptyprocess                       0.7.0\n",
            "py-cpuinfo                       9.0.0\n",
            "py4j                             0.10.9.7\n",
            "pyarrow                          17.0.0\n",
            "pyarrow-hotfix                   0.6\n",
            "pyasn1                           0.6.0\n",
            "pyasn1_modules                   0.4.0\n",
            "pycocotools                      2.0.8\n",
            "pycparser                        2.22\n",
            "pydantic                         2.8.2\n",
            "pydantic_core                    2.20.1\n",
            "pydata-google-auth               1.8.2\n",
            "pydot                            1.4.2\n",
            "pydot-ng                         2.0.0\n",
            "pydotplus                        2.0.2\n",
            "PyDrive                          1.3.1\n",
            "PyDrive2                         1.6.3\n",
            "pyerfa                           2.0.1.4\n",
            "pygame                           2.6.0\n",
            "Pygments                         2.16.1\n",
            "PyGObject                        3.42.1\n",
            "PyJWT                            2.3.0\n",
            "pymc                             5.10.4\n",
            "pymystem3                        0.2.0\n",
            "pynvjitlink-cu12                 0.3.0\n",
            "PyOpenGL                         3.1.7\n",
            "pyOpenSSL                        24.1.0\n",
            "pyparsing                        3.1.2\n",
            "pyperclip                        1.9.0\n",
            "pyproj                           3.6.1\n",
            "pyproject_hooks                  1.1.0\n",
            "pyshp                            2.3.1\n",
            "PySocks                          1.7.1\n",
            "pytensor                         2.18.6\n",
            "pytest                           7.4.4\n",
            "python-apt                       2.4.0\n",
            "python-box                       7.2.0\n",
            "python-dateutil                  2.8.2\n",
            "python-louvain                   0.16\n",
            "python-slugify                   8.0.4\n",
            "python-utils                     3.8.2\n",
            "pytz                             2023.4\n",
            "pyviz_comms                      3.0.2\n",
            "PyWavelets                       1.6.0\n",
            "PyYAML                           6.0.1\n",
            "pyzmq                            24.0.1\n",
            "qdldl                            0.1.7.post4\n",
            "qudida                           0.0.4\n",
            "ratelim                          0.1.6\n",
            "referencing                      0.35.1\n",
            "regex                            2024.5.15\n",
            "requests                         2.32.3\n",
            "requests-oauthlib                1.3.1\n",
            "requirements-parser              0.9.0\n",
            "rich                             13.7.1\n",
            "rmm-cu12                         24.4.0\n",
            "rouge-score                      0.1.2\n",
            "rpds-py                          0.19.0\n",
            "rpy2                             3.4.2\n",
            "rsa                              4.9\n",
            "safetensors                      0.4.3\n",
            "scikit-image                     0.19.3\n",
            "scikit-learn                     1.2.2\n",
            "scipy                            1.11.4\n",
            "scooby                           0.10.0\n",
            "scs                              3.2.6\n",
            "seaborn                          0.13.1\n",
            "SecretStorage                    3.3.1\n",
            "Send2Trash                       1.8.3\n",
            "sentencepiece                    0.1.99\n",
            "setuptools                       67.7.2\n",
            "shapely                          2.0.5\n",
            "shellingham                      1.5.4\n",
            "simple_parsing                   0.1.5\n",
            "six                              1.16.0\n",
            "sklearn-pandas                   2.2.0\n",
            "smart-open                       7.0.4\n",
            "sniffio                          1.3.1\n",
            "snowballstemmer                  2.2.0\n",
            "sortedcontainers                 2.4.0\n",
            "soundfile                        0.12.1\n",
            "soupsieve                        2.5\n",
            "soxr                             0.3.7\n",
            "spacy                            3.7.5\n",
            "spacy-legacy                     3.0.12\n",
            "spacy-loggers                    1.0.5\n",
            "Sphinx                           5.0.2\n",
            "sphinxcontrib-applehelp          1.0.8\n",
            "sphinxcontrib-devhelp            1.0.6\n",
            "sphinxcontrib-htmlhelp           2.0.5\n",
            "sphinxcontrib-jsmath             1.0.1\n",
            "sphinxcontrib-qthelp             1.0.7\n",
            "sphinxcontrib-serializinghtml    1.1.10\n",
            "SQLAlchemy                       2.0.31\n",
            "sqlglot                          20.11.0\n",
            "sqlparse                         0.5.0\n",
            "srsly                            2.4.8\n",
            "stanio                           0.5.1\n",
            "statsmodels                      0.14.2\n",
            "StrEnum                          0.4.15\n",
            "sympy                            1.13.0\n",
            "tables                           3.8.0\n",
            "tabulate                         0.9.0\n",
            "tbb                              2021.13.0\n",
            "tblib                            3.0.0\n",
            "tenacity                         8.5.0\n",
            "tensorboard                      2.15.2\n",
            "tensorboard-data-server          0.7.2\n",
            "tensorflow                       2.15.0\n",
            "tensorflow-datasets              4.9.6\n",
            "tensorflow-estimator             2.15.0\n",
            "tensorflow-gcs-config            2.15.0\n",
            "tensorflow-hub                   0.16.1\n",
            "tensorflow-io-gcs-filesystem     0.37.1\n",
            "tensorflow-metadata              1.15.0\n",
            "tensorflow-probability           0.23.0\n",
            "tensorstore                      0.1.45\n",
            "termcolor                        2.4.0\n",
            "terminado                        0.18.1\n",
            "text-unidecode                   1.3\n",
            "textblob                         0.17.1\n",
            "tf_keras                         2.15.1\n",
            "tf-slim                          1.1.0\n",
            "thinc                            8.2.5\n",
            "threadpoolctl                    3.5.0\n",
            "tifffile                         2024.7.2\n",
            "tinycss2                         1.3.0\n",
            "tokenizers                       0.19.1\n",
            "toml                             0.10.2\n",
            "tomli                            2.0.1\n",
            "toolz                            0.12.1\n",
            "torch                            2.3.1+cu121\n",
            "torchaudio                       2.3.1+cu121\n",
            "torchsummary                     1.5.1\n",
            "torchtext                        0.18.0\n",
            "torchvision                      0.18.1+cu121\n",
            "tornado                          6.3.3\n",
            "tqdm                             4.66.4\n",
            "traitlets                        5.7.1\n",
            "traittypes                       0.2.1\n",
            "transformers                     4.42.4\n",
            "triton                           2.3.1\n",
            "tweepy                           4.14.0\n",
            "typer                            0.12.3\n",
            "types-pytz                       2024.1.0.20240417\n",
            "types-setuptools                 70.3.0.20240710\n",
            "typing_extensions                4.12.2\n",
            "tzdata                           2024.1\n",
            "tzlocal                          5.2\n",
            "uc-micro-py                      1.0.3\n",
            "uritemplate                      4.1.1\n",
            "urllib3                          2.0.7\n",
            "vega-datasets                    0.9.0\n",
            "wadllib                          1.3.6\n",
            "wasabi                           1.1.3\n",
            "wcwidth                          0.2.13\n",
            "weasel                           0.4.1\n",
            "webcolors                        24.6.0\n",
            "webencodings                     0.5.1\n",
            "websocket-client                 1.8.0\n",
            "Werkzeug                         3.0.3\n",
            "wheel                            0.43.0\n",
            "widgetsnbextension               3.6.7\n",
            "wordcloud                        1.9.3\n",
            "wrapt                            1.14.1\n",
            "xarray                           2023.7.0\n",
            "xarray-einstats                  0.7.0\n",
            "xgboost                          2.0.3\n",
            "xlrd                             2.0.1\n",
            "xxhash                           3.4.1\n",
            "xyzservices                      2024.6.0\n",
            "yarl                             1.9.4\n",
            "yellowbrick                      1.5\n",
            "yfinance                         0.2.40\n",
            "zict                             3.0.0\n",
            "zipp                             3.19.2\n"
          ]
        }
      ],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylW2Oq3s1I5w"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import tarfile\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "91b257cc402f409986a4da14bfc29e37",
            "6aec96102628434e8337936e8644db70",
            "f33d6e804b564c33badce2c8d89423ac",
            "f4ceca315899424f990a397f8ca36e39",
            "8e9c778d3c6a4fec9879cb03920bbd75",
            "9dcd30ce5abb45e282f8374f77510dd3",
            "70420f2c87404e4d8c51de7874e23b94",
            "d51dca933b2346399d6ecfc17bfc74a9",
            "79b53f06c3e043adaf1846b6bac116ee",
            "0b630e617b4344f69e65503baa9fe328",
            "7824ef33018c41528a44bd945fbf66ff"
          ]
        },
        "id": "xVaaaKnEX5os",
        "outputId": "ef12a694-768f-40f3-be04-89d719a0b349"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91b257cc402f409986a4da14bfc29e37"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import nltk\n",
        "import evaluate\n",
        "from datasets import Dataset, DatasetDict\n",
        "from nltk.tokenize import sent_tokenize\n",
        "rouge_score = evaluate.load(\"rouge\")\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zlb8ABW38s_",
        "outputId": "ff483ab0-5f2a-40a9-a00a-f2c88b5db98b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LanVjSR14D15"
      },
      "outputs": [],
      "source": [
        "work_dir = '/content/drive/MyDrive/NLP Bootcamp/project-2_text_summarization' # change to your working directory\n",
        "os.chdir(work_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nobDZbEVzX2B"
      },
      "source": [
        "### Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWxwdY1B4X7j",
        "outputId": "fc2091ab-4577-4349-bec6-1717d5dd8957"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['liputan6_data.tar.gz',\n",
              " 'dataset',\n",
              " 'dataset_parquet',\n",
              " 'Text-Summarization.ipynb']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir(work_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhATmKgSznOv"
      },
      "outputs": [],
      "source": [
        "# I assume you already downloaded liputan6_data.tar.gz from fajrikoto/id_liputan6 (huggingface dataset)\n",
        "datasource = tarfile.open('liputan6_data.tar.gz')\n",
        "datasource.extractall('./dataset') # will create a directory of dataset/liputan6_data\n",
        "datasource.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4_17KOOznOz"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import os\n",
        "\n",
        "def get_article(json_filename_path,tobe_get_key='clean_article'):\n",
        "    '''Load json file and get article'''\n",
        "    file = open(json_filename_path,'r')\n",
        "    article_dict = json.load(file)\n",
        "    file.close()\n",
        "    return article_dict[tobe_get_key]\n",
        "\n",
        "def cleaning_article_sentence(list_sentence):\n",
        "    '''Cleaning sentences'''\n",
        "    list_sentence_clean = [' '.join(sent).replace(' .','.').replace(' ,',',').replace('( ','(').replace(' )',')').replace('. ','.').replace('\"','') for sent in list_sentence]\n",
        "    # remove \"Liputan6.com\" intro template\n",
        "    list_sentence_clean[0] = list_sentence_clean[0].split(':')[-1].strip()\n",
        "    # remove \"( xxxx )\" outro template\n",
        "    list_sentence_clean[-1] = list_sentence_clean[-1].split('.(')[0].strip()+'.'\n",
        "    pattern = '\\[.*\\]'\n",
        "    list_sentence_clean[-1] = re.sub(pattern,'',list_sentence_clean[-1]).replace(' .','.')\n",
        "    return list_sentence_clean\n",
        "\n",
        "def get_data_from_json(json_file):\n",
        "  with open(json_file, \"r\", encoding=\"utf-8\") as file:\n",
        "    data = json.load(file)\n",
        "    article = cleaning_article_sentence(data['clean_article'])\n",
        "    article = ' '.join(article)\n",
        "    article = re.sub(r'\\.{2,}', '.', article)\n",
        "    summary = cleaning_article_sentence(data['clean_summary'])\n",
        "    summary = ' '.join(summary)\n",
        "    summary = re.sub(r'\\.{2,}', '.', summary)\n",
        "    return {\"article\":article,\"summary\":summary}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDzSHUfNjjvu",
        "outputId": "4d44c261-90ba-48a7-8181-0889c853eadf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'article': 'Tim kuasa hukum Huria Kristen Batak Protestan (HKBP) Pondok Timur Indah, Bekasi, Jawa Barat, mengatakan bahwa kejadian penusukan seharusnya dapat dihindari seandainya pemerintah cepat tanggap.  Para jemaat merasa miris,  ujar Koordinator Tim Advokasi Gereja Huria Kristen Batak Protestan (HKBP) Pondok Indah Timur, Bekasi, Jawa Barat, Sahara Pangaribuan, saat ditemui di Markas Kepolisian Daerah Metro Jaya, Rabu (15/9). Ia menambahkan para jemaat sudah sejak lama merasa diamati dan pernah melaporkannya kepada Komisi Nasional Hak Asasi Manusia untuk diteruskan kepada Presiden Susilo Bambang Yudhoyono terkait pelarangan ibadah sejak sebulan lalu. Sahara mengaku kecewa dengan pihak kepolisian yang menganggap kasus penusukan jemaat HKBP sebagai kriminal murni. Ia mengatakan pihaknya sudah melaporkan masalah ini ke Mabes Polri sejak Agustus lalu sebagai kasus penghinaan terhadap agama. Konflik antara jemaat HKBP dan warga Desa Ciketing, Bekasi Timur, telah terjadi sejak beberapa tahun lalu. Kisruh ini akhirnya berujung pada penganiayaan jemaat pada 12 September silam.',\n",
              " 'summary': 'Tim kuasa hukum HKBP Pondok Timur Indah, Bekasi, mengatakan bahwa penganiayaan seharusnya bisa dihindari bila pemerintah lebih cepat mengatasi kisruh dengan warga.'}"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_data_from_json('dataset/liputan6_data/canonical/train/296458.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unvGZnm53Rt4"
      },
      "outputs": [],
      "source": [
        "import timeit\n",
        "import concurrent.futures\n",
        "import threading\n",
        "import pandas as pd\n",
        "#########################################\n",
        "# USING ASYNC TO GET DATA IN PARARELISM #\n",
        "#########################################\n",
        "def get_dataset(dir):\n",
        "  '''Get dataset from directory then do cleaning. Return dataframe consists of articles and summaries'''\n",
        "  filenames_path = list(map(lambda x:dir+'/'+x, os.listdir(dir)))\n",
        "  start_time = timeit.default_timer()\n",
        "  semaphore = threading.BoundedSemaphore(8)\n",
        "\n",
        "  with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
        "      future_articles = [executor.submit(get_data_from_json, filename) for filename in filenames_path]\n",
        "      articles = [future.result() for future in concurrent.futures.as_completed(future_articles)]\n",
        "\n",
        "  df_articles=pd.json_normalize(articles)\n",
        "  end_time = timeit.default_timer()\n",
        "\n",
        "  print(f\"Execution time: {end_time - start_time:.2f} seconds\")\n",
        "  return df_articles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtbkA8ZX3qVr",
        "outputId": "4c27806a-b441-4082-c50a-b8b2db6e5bc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Execution time: 4204.90 seconds\n"
          ]
        }
      ],
      "source": [
        "# Generate Dataset from Directory of JSONs. Only one time run.\n",
        "df_train = get_dataset('dataset/liputan6_data/canonical/train') # Execution time: 4204.90 seconds\n",
        "df_val = get_dataset('dataset/liputan6_data/canonical/dev') # Execution time: 284.85 seconds\n",
        "df_test = get_dataset('dataset/liputan6_data/canonical/test') # Execution time: 328.75 seconds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UjIGtFl92bLb",
        "outputId": "1576e127-6e4a-4f80-95a6-4fea1107c4f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fastparquet\n",
            "  Downloading fastparquet-2024.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from fastparquet) (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fastparquet) (1.25.2)\n",
            "Collecting cramjam>=2.3 (from fastparquet)\n",
            "  Downloading cramjam-2.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from fastparquet) (2023.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastparquet) (24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->fastparquet) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->fastparquet) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->fastparquet) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.16.0)\n",
            "Installing collected packages: cramjam, fastparquet\n",
            "Successfully installed cramjam-2.8.3 fastparquet-2024.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install fastparquet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ai4ktc-pLAvK"
      },
      "outputs": [],
      "source": [
        "# Export to Parquet to speed up when re-calling the dataset. Only one time run.\n",
        "df_train.to_parquet('dataset_parquet/canonical_train.parquet',engine='fastparquet')\n",
        "df_val.to_parquet('dataset_parquet/canonical_dev.parquet',engine='fastparquet')\n",
        "df_test.to_parquet('dataset_parquet/canonical_test.parquet',engine='fastparquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leR9VeZ4gBoq",
        "outputId": "64e50319-3b95-4228-c29d-e7cde650b545"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: CUDA_LAUNCH_BLOCKING=1\n"
          ]
        }
      ],
      "source": [
        "# %env CUDA_LAUNCH_BLOCKING=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxhRVV-kn6ro",
        "outputId": "adb45ae0-54e7-4047-813a-6fe0e584f57e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: TORCH_USE_CUDA_DSA=1\n"
          ]
        }
      ],
      "source": [
        "# %env TORCH_USE_CUDA_DSA=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo0h8nJzWUeC"
      },
      "source": [
        "## Get Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuiRhERF8mw3"
      },
      "outputs": [],
      "source": [
        "###################################################\n",
        "# START FROM HERE IF YOU ALREADY HAVE THE PARQUET #\n",
        "###################################################\n",
        "\n",
        "# Read parquet dataset\n",
        "df_train = pd.read_parquet('dataset_parquet/canonical_train.parquet')\n",
        "df_val = pd.read_parquet('dataset_parquet/canonical_dev.parquet')\n",
        "df_test = pd.read_parquet('dataset_parquet/canonical_test.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKSg0hLL9LQb",
        "outputId": "556656d4-e284-4335-89f2-057b0a551a02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 117278 entries, 0 to 117277\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count   Dtype \n",
            "---  ------   --------------   ----- \n",
            " 0   article  117278 non-null  object\n",
            " 1   summary  117278 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 1.8+ MB\n"
          ]
        }
      ],
      "source": [
        "df_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZxEr37e1P3v",
        "outputId": "09797240-a33b-4285-a288-91d9d8f775e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10980 entries, 0 to 10979\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   article  10980 non-null  object\n",
            " 1   summary  10980 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 171.7+ KB\n"
          ]
        }
      ],
      "source": [
        "df_val.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrpVDCQt0poU",
        "outputId": "de53a874-279f-4680-dfde-dc734a0491f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10972 entries, 0 to 10971\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   article  10972 non-null  object\n",
            " 1   summary  10972 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 171.6+ KB\n"
          ]
        }
      ],
      "source": [
        "df_test.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "sTYty5eKZrmF",
        "outputId": "5c1fcd06-3ee0-4774-944c-072fc8a61273"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-63f032ff-e150-4707-856a-eb3952646540\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sedikitnya 25 anak tewas saat bus sekolah yang...</td>\n",
              "      <td>Puluhan anak tewas saat bus sekolah yang merek...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ratusan mahasiswa dari berbagai daerah yang te...</td>\n",
              "      <td>Ratusan mahasiswa menggelar unjuk rasa di depa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Polisi kembali menembak mati dua anggota kawan...</td>\n",
              "      <td>Polisi kembali menembak mati dua anggota kawan...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63f032ff-e150-4707-856a-eb3952646540')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-63f032ff-e150-4707-856a-eb3952646540 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-63f032ff-e150-4707-856a-eb3952646540');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-99d0a910-ed62-4c91-9aaa-e9ac927c51b2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-99d0a910-ed62-4c91-9aaa-e9ac927c51b2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-99d0a910-ed62-4c91-9aaa-e9ac927c51b2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                             article  \\\n",
              "0  Sedikitnya 25 anak tewas saat bus sekolah yang...   \n",
              "1  Ratusan mahasiswa dari berbagai daerah yang te...   \n",
              "2  Polisi kembali menembak mati dua anggota kawan...   \n",
              "\n",
              "                                             summary  \n",
              "0  Puluhan anak tewas saat bus sekolah yang merek...  \n",
              "1  Ratusan mahasiswa menggelar unjuk rasa di depa...  \n",
              "2  Polisi kembali menembak mati dua anggota kawan...  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "kkFsV3Dd1SlW",
        "outputId": "be4d8991-3021-4761-a369-8ef05e2b7e8e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_test\",\n  \"rows\": 10972,\n  \"fields\": [\n    {\n      \"column\": \"article\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10970,\n        \"samples\": [\n          \"Dalam waktu dekat Indonesia akan menyelesaikan laporan soal terorisme dan penanganannya kepada Dewan Keamanan Perserikatan Bangsa Bangsa. Hal tersebut dilakukan mengingat seluruh negara diwajibkan PBB untuk memberi laporan mengenai penanganan terorisme yang ada di wilayah negara masing-masing. Saat ini pemerintah masih menyusun laporan mengenai penanganan terorisme yang kemungkinan ada di Indonesia. Demikian disampaikan Menteri Luar Negeri Hassan Wirajuda, seusai mengikuti rapat kabinet di Kantor Sekretariat Negara Jakarta, Kamis (25/10) siang. Menurut Hassan, laporan tersebut menjadi kewajiban Indonesia setelah Resolusi PBB Nomor 1373 disahkan, 28 September silam. Sayangnya, Hassan Wirajuda tak bersedia mengumumkan substansi laporan tersebut kepada publik. Kendati begitu, laporan pemerintah adalah hasil koordinasi antardepartemen dalam dua pertemuan terdahulu. Mereka yang hadir adalah wakil-wakil menteri koordinator politik dan keamanan, menko perekonomian, Badan Intelijen Negara, kepolisian, Kejaksaan Agung, Departemen Keuangan, dan Departemen Perhubungan. Hassan menegaskan, dalam waktu dekat masih akan ada pertemuan-pertemuan serupa untuk memantapkan laporan tersebut.\",\n          \"Ketua Umum DPP Partai Golkar Akbar Tandjung mendukung rencana Presiden Megawati Sukarnoputri memberikan abolisi kepada mantan Presiden Soeharto. Pasalnya, pemberian abolisi adalah hak presiden sepenuhnya. Terlebih lagi, rencana tersebut juga sangat pantas diberikan bila berdasarkan pertimbangan kemanusiaan. Hal ini diungkapkan Akbar Tandjung seusai acara apel akbar Partai Golkar Sumatra Barat di Tanjungpati, Kabupaten Limapuluhkota, baru-baru ini. Akbar yang juga Ketua DPR mengatakan bahwa abolisi dapat diberikan setelah presiden mendapatkan pertimbangan anggota Dewan. Kendati hingga saat ini belum dilakukan presiden, Akbar menilai mantan penguasa Orde Baru itu layak diampuni. Sejatinya, Akbar meminta presiden memperhatikan kondisi Soeharto yang tengah sakit permanen. Apalagi, setiap omongan ayah Hutomo Mandala Putra itu juga sulit dimengerti. Sedangkan berkaitan dengan apel partai berlambang pohon beringin yang dihadiri ribuan massanya itu, Akbar juga mengungkapkan dirinya siap menunggu keputusan Kejaksaan Agung, 7 Januari mendatang. Sedianya, Kejagung bakal memberikan keputusan tentang dugaan keterlibatan Akbar dalam kasus penyelewengan dana nonbujeter Badan Urusan Logistik sebesar Rp 54, 6 miliar.\",\n          \"Sikap mantan Presiden Abdurrahman Wahid yang tetap bertahan di Istana Merdeka dinilai sejumlah aktivis sebagai tindakan yang akan menimbulkan persoalan baru. Karena itu, baru-baru ini, mereka meminta agar Gus Dur segera meninggalkan Kompleks Istana Merdeka, Jakarta Pusat. Di sisi lain, mereka meminta agar Presiden Megawati Sukarnoputri bersikap kooperatif dalam upaya membawa Gus Dur keluar dari Istana. Seorang fungsionaris Partai Amanat Nasional Bara Hasibuan berpendapat, Presiden Megawati perlu berinisiatif mengambil langkah-langkah untuk merangkul mantan Presiden Wahid. Ia menilai hal itu akan sangat berarti bagi proses rekonsiliasi yang sedang berlangsung. Sementara, Putri bungsu Gus Dur, Inayah Wulandari yang berusia 18 tahun seakan tak perduli dengan pencabutan mandat terhadap ayahnya sebagai presiden RI. Inayah mengaku, kembali ke kehidupan biasa, layaknya anggota masyarakat yang jauh dari aturan protokoler adalah suatu hal yang sangat menggembirakan. Dari pemantauan SCTV, saat mantan Presiden Wahid tengah beristirahat, Selasa kemarin, mahasiswi Fakultas Sastra Universitas Indonesia itu menggunakan kesempatan untuk berjalan-jalan keliling Kompleks Istana Merdeka dengan sebuah golf cart yang biasa digunakan presiden. Namun, Inayah mengaku belum tahu kapan akan keluar dari Istana, meski mengungkapkan bahwa keluarganya sudah berkemas-kemas.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10967,\n        \"samples\": [\n          \"Pemilu 2004 diharapkan menggunakan sistim pemilihan presiden langsung. Semuanya tergantung dari kemauan politik pemerintah dan partai politik.\",\n          \"Seluruh lembaga tinggi mesti mempertanggungjawabkan hasil kerjanya kepada MPR dalam sidang tahunan. DPR tak perlu menyampaikan progress report.\",\n          \"Untuk menyelamatkan harta negara, Kejaksaan Agung akan menuntut bekas Presiden Soeharto secara perdata. Mestinya Soeharto diusut dalam kasus penyalahgunaan kekuasaan untuk menerbitkan surat keputusan.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_test"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-d010dc6e-68bb-4d98-b343-b7d82b352bbb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sekitar 300 preman dari berbagai wilayah rawan...</td>\n",
              "      <td>Selama bulan Ramadan, ratusan preman di Kota M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tiga dari lima orang resmi menjadi tersangka d...</td>\n",
              "      <td>Polisi menetapkan tiga dari lima orang sebagai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kerusakan parah di sepanjang jalan lintas teng...</td>\n",
              "      <td>Sejumlah kerusakan di sepanjang jalan lintas t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d010dc6e-68bb-4d98-b343-b7d82b352bbb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d010dc6e-68bb-4d98-b343-b7d82b352bbb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d010dc6e-68bb-4d98-b343-b7d82b352bbb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-024c9de1-091e-4806-8e0b-d853ff4629a2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-024c9de1-091e-4806-8e0b-d853ff4629a2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-024c9de1-091e-4806-8e0b-d853ff4629a2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                             article  \\\n",
              "0  Sekitar 300 preman dari berbagai wilayah rawan...   \n",
              "1  Tiga dari lima orang resmi menjadi tersangka d...   \n",
              "2  Kerusakan parah di sepanjang jalan lintas teng...   \n",
              "\n",
              "                                             summary  \n",
              "0  Selama bulan Ramadan, ratusan preman di Kota M...  \n",
              "1  Polisi menetapkan tiga dari lima orang sebagai...  \n",
              "2  Sejumlah kerusakan di sepanjang jalan lintas t...  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "nmRpjIBO1VL_",
        "outputId": "bd72e004-4bd2-4978-e407-ba9e3ca6602e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_val\",\n  \"rows\": 10980,\n  \"fields\": [\n    {\n      \"column\": \"article\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10961,\n        \"samples\": [\n          \"Lima dari beberapa gadis yang menjadi korban pemerkosaan asal Kota Fajar, Aceh Selatan, mendatangi Kantor Komisi Nasional Hak Asasi Manusia Cabang Aceh, baru-baru ini. Mereka mengaku telah diperkosa anggota Brigade Mobil Polri yang bertugas di daerahnya. Itu sebabnya, Ketua Komisi untuk Orang Hilang dan Anti Kekerasan Aceh Aguswandi di Banda Aceh, menuntut pelakunya bertanggung jawab dan ditindak tegas. Kepala Perwakilan Komnas HAM Aceh Iqbal Faraby menyesalkan kasus pemerkosaan dan kekerasan terhadap wanita masih terjadi. Iqbal menilai, tindakan tersebut sebagai strategi untuk melumpuhkan kekuatan sipil. Menanggapi tudingan tersebut, Wakil Kepala Penerangan Operasi Cinta Meunasah 2000 Yatim Suyatmo membantah. Ia mengatakan, tuduhan itu hanyalah rekayasa dari Gerakan Aceh Merdeka untuk merusak citra aparat keamanan.\",\n          \"Presiden Abdurrahman Wahid diminta untuk tak memberlakukan keadaan darurat. Sebab, hal itu justru akan membuat kondisi bangsa semakin lebih buruk. Permintaan itu disampaikan Kepala Staf TNI Angkatan Darat Jenderal TNI Endriartono Sutarto seusai menghadiri pembukaan Rapat Pembinaan Teknis dan Kecabangan TNI AD, di Bandung, Jawa Barat, Senin (14/5). Menurut Endriartono, keadaan darurat baru bisa dilaksanakan jika integritas bangsa benar-benar terancam. Untuk itu, TNI tak akan mendukung rencana Gus Dur itu. Terlebih, tambah KSAD, bila keinginan itu semata-mata digunakan untuk mempertahankan kekuasaan Presiden.  Dengan tegas TNI AD menolak,  kata Endriartono. Namun demikian, jelas Endriartono, TNI akan mendukung andai Gus Dur berencana memberlakukan keadaan darurat di Aceh dan Irianjaya.  Sebab, kondisi ke dua daerah itu memang terancam,  ujar Endriartono. Pada kesempatan itu, Endriartono juga menegaskan TNI akan berupaya semaksimal mungkin menjamin keselamatan bangsa dan negara. Lantaran itu, TNI tak akan mentolerir siapa pun untuk melakukan langkah-langkah yang dapat menciptakan kekacauan serta memperburuk situasi negara.\",\n          \"Teka-teki bentuk kepulauan Nusantara di abad 15 tampaknya sedikit terjawab. Soalnya, Francisco Rodrigues, seorang pelaut asal Portugis, ternyata pernah membuat sebuah peta Nusantara ketika ia melakukan ekspedisi antara tahun 1512 sampai 1514. Kini, karya luar biasa itu dapat dinikmati dalam sebuah pameran lukisan yang digelar di Gedung Arsip Nasional, Jakarta. Sejumlah hasil karya Francisco Rodrigues ini dianggap penting, karena menggambarkan kepulauan nusantara sebagai negara penghasil rempah-rempah. Dalam beberapa lukisan yang ada juga digambarkan bahwa Bangsa Portugis pernah melakukan hubungan dengan beberapa bangsa di Asia Tenggara, termasuk dengan Kepulauan Nusantara. Selain lukisan, Francisco juga menampilkan beberapa buku karyanya. Sayangnya, tak semua buku bisa dipublikasikan, karena Francisco keburu meninggal sebelum ia menyelesaikan ekspedisinya. Dalam pameran kali ini, panitia menggelar 69 lukisan pemandangan dari berbagai pelosok dunia dan 26 peta. Dari jumlah itu, 38 halaman gambar adalah peta Kepulauan Nusantara. Peta itu, tentu saja tak bisa dibandingkan dengan peta yang dibuat dengan teknologi satelit, seperti yang diproduksi belakangan ini. Kendati karya-karya Francisco memiliki nilai sejarah yang tinggi, masyarakat tampaknya masih enggan untuk melihat pameran tersebut. Gejala itu bisa dilihat dari sepinya pengunjung ke ruang pameran.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10958,\n        \"samples\": [\n          \"IMF menunda pengucuran dana. Bank Dunia pun berencana akan mengehentikan semua bentuk pinjaman baru untuk Indonesia. Gross Domestic Product diprediksi hanya empat persen.\",\n          \"Selain menodai demokrasi di Indonesia, kompromi politik dinilai tak efektif. Kompromi politik sebaiknya dilakukan secara terbuka dan melibatkan para tokoh partai politik.\",\n          \"Lantaran harga BBM dan harga argo taksi naik, sekitar 800 sopir Bali Taksi mogok kerja. Mereka menuntut penurunan setoran dan kenaikan tunjangan kesepian.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_val"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-0d08d77c-798a-4cf3-ae65-1c87eab3c08e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Menteri Luar Negeri Alwi Shihab, Rabu (22/11) ...</td>\n",
              "      <td>Dua negara kecil di Pasifik mengusulkan Irianj...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tim Reserse Kepolisian Kota Besar Medan mering...</td>\n",
              "      <td>Dua anggota sindikat pengedar ganja asal Aceh ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Panitia Khusus Rancangan Undang-undang (RUU) O...</td>\n",
              "      <td>Pemerintah dan anggota Panitia Khusus RUU Oton...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d08d77c-798a-4cf3-ae65-1c87eab3c08e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0d08d77c-798a-4cf3-ae65-1c87eab3c08e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0d08d77c-798a-4cf3-ae65-1c87eab3c08e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5809f5d3-88aa-4bcd-bcf5-20c597abb37c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5809f5d3-88aa-4bcd-bcf5-20c597abb37c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5809f5d3-88aa-4bcd-bcf5-20c597abb37c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                             article  \\\n",
              "0  Menteri Luar Negeri Alwi Shihab, Rabu (22/11) ...   \n",
              "1  Tim Reserse Kepolisian Kota Besar Medan mering...   \n",
              "2  Panitia Khusus Rancangan Undang-undang (RUU) O...   \n",
              "\n",
              "                                             summary  \n",
              "0  Dua negara kecil di Pasifik mengusulkan Irianj...  \n",
              "1  Dua anggota sindikat pengedar ganja asal Aceh ...  \n",
              "2  Pemerintah dan anggota Panitia Khusus RUU Oton...  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_val.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcFZXBo-COfy"
      },
      "outputs": [],
      "source": [
        "# Due to computational resource limitation, We will just use sampling data from original data\n",
        "import random\n",
        "random.seed(101)\n",
        "\n",
        "train_idx = random.choices(df_train.index,k=35000)\n",
        "df_train_used = df_train.iloc[train_idx].reset_index(drop=True)\n",
        "\n",
        "val_idx = random.choices(df_val.index,k=2000)\n",
        "df_val_used = df_val.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "test_idx = random.choices(df_test.index,k=2000)\n",
        "df_test_used = df_test.iloc[test_idx].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jai-bN40bzBU"
      },
      "source": [
        "### EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "vkv5cGM1de9E",
        "outputId": "cd25b77f-d2d7-4c7f-d7bf-36804c02fcbd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_eda_raw\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"total_sentence_article\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 41445.22277968491,\n        \"min\": 1.0,\n        \"max\": 117278.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          12.640341752076264,\n          10.0,\n          117278.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_words_article\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 41124.94021049299,\n        \"min\": 35.0,\n        \"max\": 117278.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          220.03893313323897,\n          181.0,\n          117278.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_sentence_summary\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 41462.98660733728,\n        \"min\": 0.6629776285569857,\n        \"max\": 117278.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          117278.0,\n          2.087706134142806,\n          11.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_words_summary\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 41452.41860764974,\n        \"min\": 1.0,\n        \"max\": 117278.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          30.822890908780845,\n          30.0,\n          117278.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ae08734f-f192-4635-8a05-fc95a91923c4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_sentence_article</th>\n",
              "      <th>total_words_article</th>\n",
              "      <th>total_sentence_summary</th>\n",
              "      <th>total_words_summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>117278.000000</td>\n",
              "      <td>117278.000000</td>\n",
              "      <td>117278.000000</td>\n",
              "      <td>117278.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>12.640342</td>\n",
              "      <td>220.038933</td>\n",
              "      <td>2.087706</td>\n",
              "      <td>30.822891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>8.642474</td>\n",
              "      <td>139.551666</td>\n",
              "      <td>0.662978</td>\n",
              "      <td>7.373094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.000000</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>27.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>181.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>30.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>15.000000</td>\n",
              "      <td>262.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>34.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>320.000000</td>\n",
              "      <td>7206.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae08734f-f192-4635-8a05-fc95a91923c4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ae08734f-f192-4635-8a05-fc95a91923c4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ae08734f-f192-4635-8a05-fc95a91923c4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e4eea03c-ba54-4194-8193-661b059aef19\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e4eea03c-ba54-4194-8193-661b059aef19')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e4eea03c-ba54-4194-8193-661b059aef19 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       total_sentence_article  total_words_article  total_sentence_summary  \\\n",
              "count           117278.000000        117278.000000           117278.000000   \n",
              "mean                12.640342           220.038933                2.087706   \n",
              "std                  8.642474           139.551666                0.662978   \n",
              "min                  1.000000            35.000000                1.000000   \n",
              "25%                  8.000000           135.000000                2.000000   \n",
              "50%                 10.000000           181.000000                2.000000   \n",
              "75%                 15.000000           262.000000                2.000000   \n",
              "max                320.000000          7206.000000               11.000000   \n",
              "\n",
              "       total_words_summary  \n",
              "count        117278.000000  \n",
              "mean             30.822891  \n",
              "std               7.373094  \n",
              "min               1.000000  \n",
              "25%              27.000000  \n",
              "50%              30.000000  \n",
              "75%              34.000000  \n",
              "max             100.000000  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Total Sentence and Word from Train Dataframe (Raw)\n",
        "df_eda_raw = pd.DataFrame()\n",
        "\n",
        "df_eda_raw['total_sentence_article'] = df_train['article'].apply(lambda x:len(nltk.sent_tokenize(x)))\n",
        "df_eda_raw['total_words_article'] = df_train['article'].apply(lambda x:len(nltk.word_tokenize(x)))\n",
        "df_eda_raw['total_sentence_summary'] = df_train['summary'].apply(lambda x:len(nltk.sent_tokenize(x)))\n",
        "df_eda_raw['total_words_summary'] = df_train['summary'].apply(lambda x:len(nltk.word_tokenize(x)))\n",
        "\n",
        "df_eda_raw.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "g9oCRSz2bjOE",
        "outputId": "4f5a37b2-273e-4a55-fc34-cd10253bad6b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_eda\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"total_sentence_article\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12356.492293006315,\n        \"min\": 1.0,\n        \"max\": 35000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          12.675485714285715,\n          10.0,\n          35000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_words_article\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12205.201363437143,\n        \"min\": 41.0,\n        \"max\": 35000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          220.6612,\n          182.0,\n          35000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_sentence_summary\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12373.321162272237,\n        \"min\": 0.6625296691668051,\n        \"max\": 35000.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          35000.0,\n          2.085914285714286,\n          11.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_words_summary\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12362.827185371698,\n        \"min\": 2.0,\n        \"max\": 35000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          30.824857142857145,\n          30.0,\n          35000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-1a42924e-9350-432d-a8ca-42ade3746a6f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_sentence_article</th>\n",
              "      <th>total_words_article</th>\n",
              "      <th>total_sentence_summary</th>\n",
              "      <th>total_words_summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>35000.000000</td>\n",
              "      <td>35000.000000</td>\n",
              "      <td>35000.000000</td>\n",
              "      <td>35000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>12.675486</td>\n",
              "      <td>220.661200</td>\n",
              "      <td>2.085914</td>\n",
              "      <td>30.824857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>8.967807</td>\n",
              "      <td>142.267167</td>\n",
              "      <td>0.662530</td>\n",
              "      <td>7.359093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.000000</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>27.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>182.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>30.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>15.000000</td>\n",
              "      <td>261.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>34.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>307.000000</td>\n",
              "      <td>3438.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>98.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a42924e-9350-432d-a8ca-42ade3746a6f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1a42924e-9350-432d-a8ca-42ade3746a6f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1a42924e-9350-432d-a8ca-42ade3746a6f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4611215f-6d03-4464-b0f1-ab20cf760ef1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4611215f-6d03-4464-b0f1-ab20cf760ef1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4611215f-6d03-4464-b0f1-ab20cf760ef1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       total_sentence_article  total_words_article  total_sentence_summary  \\\n",
              "count            35000.000000         35000.000000            35000.000000   \n",
              "mean                12.675486           220.661200                2.085914   \n",
              "std                  8.967807           142.267167                0.662530   \n",
              "min                  1.000000            41.000000                1.000000   \n",
              "25%                  8.000000           135.000000                2.000000   \n",
              "50%                 10.000000           182.000000                2.000000   \n",
              "75%                 15.000000           261.000000                2.000000   \n",
              "max                307.000000          3438.000000               11.000000   \n",
              "\n",
              "       total_words_summary  \n",
              "count         35000.000000  \n",
              "mean             30.824857  \n",
              "std               7.359093  \n",
              "min               2.000000  \n",
              "25%              27.000000  \n",
              "50%              30.000000  \n",
              "75%              34.000000  \n",
              "max              98.000000  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Total Sentence and Word from Train Dataframe (Used)\n",
        "df_eda = pd.DataFrame()\n",
        "\n",
        "df_eda['total_sentence_article'] = df_train_used['article'].apply(lambda x:len(nltk.sent_tokenize(x)))\n",
        "df_eda['total_words_article'] = df_train_used['article'].apply(lambda x:len(nltk.word_tokenize(x)))\n",
        "df_eda['total_sentence_summary'] = df_train_used['summary'].apply(lambda x:len(nltk.sent_tokenize(x)))\n",
        "df_eda['total_words_summary'] = df_train_used['summary'].apply(lambda x:len(nltk.word_tokenize(x)))\n",
        "\n",
        "df_eda.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lArbAfSvfu57",
        "outputId": "9c7e0428-ac67-43c4-b5e2-aca03ec77438"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-25-222f5fd5c04b>:2: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
            "  plt.style.use(\"seaborn\")\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"seaborn\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "z4CmRV3ndUP2",
        "outputId": "0ce17a64-7c0e-4005-8b56-bed6b106027e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
        "\n",
        "# Plot the first histogram\n",
        "ax1.hist(df_eda_raw['total_sentence_article'], bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
        "ax1.set_title('Total Sentence Article (Train Raw)')\n",
        "ax1.set_xlabel('Total Sentence in a Article')\n",
        "ax1.set_ylabel('Frequency')\n",
        "\n",
        "# Plot the second histogram\n",
        "ax2.hist(df_eda['total_sentence_article'], bins=50, alpha=0.7, color='green', edgecolor='black')\n",
        "ax2.set_title('Total Sentence Article (Train Used)')\n",
        "ax2.set_xlabel('Total Sentence in a Article')\n",
        "ax2.set_ylabel('Frequency')\n",
        "\n",
        "# Adjust the layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Adjust the layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plots\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "9yhk5Jw_gEi6",
        "outputId": "0c29b7b8-a407-4d4b-9bfe-b76cd6c09b48"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
        "\n",
        "# Plot the first histogram\n",
        "ax1.hist(df_eda_raw['total_words_article'], bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
        "ax1.set_title('Total Word Article (Train Raw)')\n",
        "ax1.set_xlabel('Total Word in a Article')\n",
        "ax1.set_ylabel('Frequency')\n",
        "\n",
        "# Plot the second histogram\n",
        "ax2.hist(df_eda['total_words_article'], bins=50, alpha=0.7, color='green', edgecolor='black')\n",
        "ax2.set_title('Total Word Article (Train Used)')\n",
        "ax2.set_xlabel('Total Word in a Article')\n",
        "ax2.set_ylabel('Frequency')\n",
        "\n",
        "# Adjust the layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Adjust the layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plots\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "tPy-4uKnhM2o",
        "outputId": "7d1e19b7-d04a-4411-9f03-c7803f7af89f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
        "\n",
        "# Plot the first histogram\n",
        "ax1.hist(df_eda_raw['total_sentence_summary'], bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
        "ax1.set_title('Total Sentence Summary (Train Raw)')\n",
        "ax1.set_xlabel('Total Sentence in a Summary')\n",
        "ax1.set_ylabel('Frequency')\n",
        "\n",
        "# Plot the second histogram\n",
        "ax2.hist(df_eda['total_sentence_summary'], bins=50, alpha=0.7, color='green', edgecolor='black')\n",
        "ax2.set_title('Total Sentence Summary (Train Used)')\n",
        "ax2.set_xlabel('Total Sentence in a Summary')\n",
        "ax2.set_ylabel('Frequency')\n",
        "\n",
        "# Adjust the layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Adjust the layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plots\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "b5QvL1s4hMtq",
        "outputId": "6846466d-700b-4d03-809b-c0edce3c1de8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
        "\n",
        "# Plot the first histogram\n",
        "ax1.hist(df_eda_raw['total_words_summary'], bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
        "ax1.set_title('Total Word Summary (Train Raw)')\n",
        "ax1.set_xlabel('Total Word in a Summary')\n",
        "ax1.set_ylabel('Frequency')\n",
        "\n",
        "# Plot the second histogram\n",
        "ax2.hist(df_eda['total_words_summary'], bins=50, alpha=0.7, color='green', edgecolor='black')\n",
        "ax2.set_title('Total Word Summary (Train Used)')\n",
        "ax2.set_xlabel('Total Word in a Summary')\n",
        "ax2.set_ylabel('Frequency')\n",
        "\n",
        "# Adjust the layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Adjust the layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plots\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcFZ4s7YiU-k"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jj9gkUvFYNP"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "dataset_train = Dataset.from_pandas(df_train_used)\n",
        "dataset_val = Dataset.from_pandas(df_val_used)\n",
        "dataset_test = Dataset.from_pandas(df_test_used)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikgIc0lVJmsL"
      },
      "outputs": [],
      "source": [
        "datasets = DatasetDict({\n",
        "    'train': dataset_train,\n",
        "    'validation': dataset_val,\n",
        "    'test': dataset_test\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGLP3BrimEhx",
        "outputId": "ba097f16-deb5-47cc-a59d-eb25c667d577"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['article', 'summary'],\n",
              "        num_rows: 35000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['article', 'summary'],\n",
              "        num_rows: 2000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['article', 'summary'],\n",
              "        num_rows: 2000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cM3S5fgmQoK-"
      },
      "source": [
        "## Fine Tuning: indolem/indobert-base-uncased"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEn9OY3UQnb6"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel, EncoderDecoderModel, TrainingArguments, Trainer, DataCollatorForSeq2Seq, EarlyStoppingCallback\n",
        "import evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71Wl7xncQ0kJ"
      },
      "outputs": [],
      "source": [
        "model_checkpoint = 'indolem/indobert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "model = EncoderDecoderModel.from_encoder_decoder_pretrained(encoder_pretrained_model_name_or_path=model_checkpoint,\n",
        "                                                            decoder_pretrained_model_name_or_path=model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "26e48407188441d8949ee498ce5c62f4",
            "805d42b7630f491b867cc0912ebdef88",
            "96f2294f03264a27a5cb53e4b5c07456",
            "5931550b9602490297504aa8a7e4acdc",
            "976895ca7c6b46f3a59046834b02843a",
            "4338cadfff914a82beef8cbd09c87e38",
            "b67de56ff70948c0a392fae76864023a",
            "022166a0835d41698b603190fdc8278c",
            "3980e98eb9c8469b97834110bec08caa",
            "a92d7ec8cddd40c996f5ea535697f189",
            "6329a4a3fc1e468db51c1b3c0954f26b",
            "f73116f8599149f8bd1da4ed771a83bb",
            "4330435f245041878691b5943db20871",
            "90071ca104694ddfafa86c56e14ec4b2",
            "6562e966c9a845f2b2f9e183cd59a6c1",
            "87a7ee82377047ea8ab5eb391fa94a07",
            "eea59f99414547f38060d9939cfa3f58",
            "5fdcb29d372d40c8aa3873ebe2a33e52",
            "f551b657780246179f176e4b0e827602",
            "059ad1ebb1cb469882dc27b1c829aa6e",
            "d07bba41e7514715b80a539382b2fc04",
            "691afa7a69094f9899c901b5492f8f30",
            "f7adf02e6cba4869b732971161baf043",
            "7245ef7cabcf4b35bfabd32df4092936",
            "4517b6ecf6d347a4a201d57ae567ed7a",
            "5d9fc12f767f408696e5244fc84c587d",
            "5544413bb07f499e810c31a8b28298b5",
            "59403dd61140474b98b09ca21551387b",
            "8855b5c10f16479a8d4c4be31f0ad502",
            "6a32d06725b64ad29328e84abe364711",
            "b33498653c594348ac5034e8cf55365c",
            "732bbd6c9f78414b99e11cae1ed0c487",
            "906e0e1033bd43bc8d7dbef4f2291e16"
          ]
        },
        "id": "6XIgO-6pRFls",
        "outputId": "ca9cce1b-49b2-42e3-8ff0-f38ae3b4ffb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/35000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26e48407188441d8949ee498ce5c62f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f73116f8599149f8bd1da4ed771a83bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7adf02e6cba4869b732971161baf043"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "max_input_length = 512\n",
        "max_target_length = 128\n",
        "\n",
        "def tokenize_function(text):\n",
        "    model_inputs = tokenizer(text['article'], max_length=max_input_length, truncation=True,)\n",
        "    labels = tokenizer(text['summary'], max_length=max_target_length, truncation=True)\n",
        "    return {\n",
        "        'input_ids': model_inputs['input_ids'],\n",
        "        'attention_mask': model_inputs['attention_mask'],\n",
        "        'labels': labels[\"input_ids\"],\n",
        "    }\n",
        "\n",
        "tokenized_datasets = datasets.map(tokenize_function,batched=True, num_proc=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lQSr4yjUBHe"
      },
      "outputs": [],
      "source": [
        "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "model.config.vocab_size = model.config.encoder.vocab_size\n",
        "\n",
        "model.config.encoder.max_length = 512\n",
        "model.config.decoder.max_length = 128\n",
        "model.config.decoder.min_length = 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trtSenUfUV6M"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQeRf8dpUA_e"
      },
      "outputs": [],
      "source": [
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=f\"{model_name}-checkpoint\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    gradient_accumulation_steps=1,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=8,\n",
        "    warmup_steps=5,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy='epoch',\n",
        "    load_best_model_at_end = True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0yq9MMYUy47"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0M_fQOkAU08v",
        "outputId": "1f48f31b-fe53-4b01-86dc-84b35052f974"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (None), or the `sep_token_id` (None), and your input is not padded.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='33248' max='35000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [33248/35000 8:29:59 < 26:52, 1.09 it/s, Epoch 7.60/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.284600</td>\n",
              "      <td>3.230221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.720900</td>\n",
              "      <td>3.029064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.208300</td>\n",
              "      <td>2.800345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.822800</td>\n",
              "      <td>2.696049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.561100</td>\n",
              "      <td>2.680530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.365700</td>\n",
              "      <td>2.701562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.210600</td>\n",
              "      <td>2.723278</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DQGPCoIF_9bw",
        "outputId": "f3de68b7-c51f-441e-8923-fe8f856c709d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/NLP Bootcamp/project-2_text_summarization'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "xUBx-Xn3_7BW",
        "outputId": "66fce156-efb4-4cdd-dbfc-83670087786f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are resuming training from a checkpoint trained with 4.41.2 of Transformers but your current version is 4.42.4. This is not recommended and could yield to errors or unwanted behaviors.\n",
            "There were missing keys in the checkpoint model loaded: ['decoder.cls.predictions.decoder.weight', 'decoder.cls.predictions.decoder.bias'].\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (None), or the `sep_token_id` (None), and your input is not padded.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='35000' max='35000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [35000/35000 1:07:48, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.135000</td>\n",
              "      <td>2.737649</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "There were missing keys in the checkpoint model loaded: ['decoder.cls.predictions.decoder.weight', 'decoder.cls.predictions.decoder.bias'].\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=35000, training_loss=0.14352016078404017, metrics={'train_runtime': 4071.6887, 'train_samples_per_second': 68.768, 'train_steps_per_second': 8.596, 'total_flos': 1.4259330671863622e+17, 'train_loss': 0.14352016078404017, 'epoch': 8.0})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "trainer.train(\"./indobert-base-uncased-checkpoint/checkpoint-30625\") # resumming training from checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7FKLAcBdu1D"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"./fine_tuned_indobert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CX3Q4ndBd9ne"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM,AutoModel,EncoderDecoderModel,AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./fine_tuned_indobert-base-uncased\")\n",
        "inference_model = EncoderDecoderModel.from_pretrained(\"./fine_tuned_indobert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "QDe8JjxpnEIX",
        "outputId": "882081b2-8e50-4b46-8690-978eb6f5ba6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 01:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 2.411294937133789,\n",
              " 'eval_runtime': 61.2171,\n",
              " 'eval_samples_per_second': 32.671,\n",
              " 'eval_steps_per_second': 4.084,\n",
              " 'epoch': 8.0}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "trainer.evaluate(tokenized_datasets['test'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_used"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "6awnsTbgrjCr",
        "outputId": "8acea854-3b8a-4006-cce1-807676f29618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                article  \\\n",
              "0     Terungkapnya jaringan pencurian kendaraan berm...   \n",
              "1     Permintaan pemerintah agar Sidang Paripurna DP...   \n",
              "2     Puluhan mahasiswa yang tergabung dalam Jaringa...   \n",
              "3     Badan Penyehatan Perbankan Nasional tetap mela...   \n",
              "4     Pemerintah terus berupaya memprakarsai islah n...   \n",
              "...                                                 ...   \n",
              "1995  Tak ada yang penting dari kunjungan Presiden M...   \n",
              "1996  Praktik percaloan dan penipuan oleh perusahaan...   \n",
              "1997  Terapi analisa perilaku terapan (apllied behav...   \n",
              "1998  Ketua Front Pembela Islam Habib Rizique Shihab...   \n",
              "1999  Hingga sembilan hari setelah Lebaran, sudah se...   \n",
              "\n",
              "                                                summary  \n",
              "0     Petugas Polresta Bukit Tinggi meringkus komplo...  \n",
              "1     Badan Musyawarah DPR berharap pelaksanaan Sida...  \n",
              "2     Presiden Megawati Sukarnoputri diminta menguta...  \n",
              "3     Badan Penyehatan Perbankan Nasional tetap memp...  \n",
              "4     Pemerintah terus berupaya memprakarsai islah n...  \n",
              "...                                                 ...  \n",
              "1995  Kedatangan Presiden Megawati ke Aceh tak memil...  \n",
              "1996  Para calon penumpang mesti membeli tiket secar...  \n",
              "1997  Penderita autisme harus mendapatkan terapi unt...  \n",
              "1998  Front Pembela Islam menyatakan tak mampu mence...  \n",
              "1999  Puluhan PO bus di Lampung bakal diberi sanksi ...  \n",
              "\n",
              "[2000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aca51e98-78be-4676-8796-75f7611bb84f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Terungkapnya jaringan pencurian kendaraan berm...</td>\n",
              "      <td>Petugas Polresta Bukit Tinggi meringkus komplo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Permintaan pemerintah agar Sidang Paripurna DP...</td>\n",
              "      <td>Badan Musyawarah DPR berharap pelaksanaan Sida...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Puluhan mahasiswa yang tergabung dalam Jaringa...</td>\n",
              "      <td>Presiden Megawati Sukarnoputri diminta menguta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Badan Penyehatan Perbankan Nasional tetap mela...</td>\n",
              "      <td>Badan Penyehatan Perbankan Nasional tetap memp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pemerintah terus berupaya memprakarsai islah n...</td>\n",
              "      <td>Pemerintah terus berupaya memprakarsai islah n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>Tak ada yang penting dari kunjungan Presiden M...</td>\n",
              "      <td>Kedatangan Presiden Megawati ke Aceh tak memil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>Praktik percaloan dan penipuan oleh perusahaan...</td>\n",
              "      <td>Para calon penumpang mesti membeli tiket secar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>Terapi analisa perilaku terapan (apllied behav...</td>\n",
              "      <td>Penderita autisme harus mendapatkan terapi unt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>Ketua Front Pembela Islam Habib Rizique Shihab...</td>\n",
              "      <td>Front Pembela Islam menyatakan tak mampu mence...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>Hingga sembilan hari setelah Lebaran, sudah se...</td>\n",
              "      <td>Puluhan PO bus di Lampung bakal diberi sanksi ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aca51e98-78be-4676-8796-75f7611bb84f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aca51e98-78be-4676-8796-75f7611bb84f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aca51e98-78be-4676-8796-75f7611bb84f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dad7b77c-a78f-447f-9c0f-ba724c89c8e7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dad7b77c-a78f-447f-9c0f-ba724c89c8e7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dad7b77c-a78f-447f-9c0f-ba724c89c8e7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_b89863df-aa5d-42a2-bad7-8ade46584a2a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_test_used')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b89863df-aa5d-42a2-bad7-8ade46584a2a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_test_used');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test_used",
              "summary": "{\n  \"name\": \"df_test_used\",\n  \"rows\": 2000,\n  \"fields\": [\n    {\n      \"column\": \"article\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1819,\n        \"samples\": [\n          \"Pemerintah dinilai belum memperhatikan industri obat tradisional, khususnya jamu. Padahal, di Indonesia ada sepuluh ribu spesies tanaman yang dapat dijadikan bahan baku jamu.  Hal ini terbukti dengan belum disejajarkannya jamu dengan obat-obatan farmasi,  kata Kusmayanto Kadiman, pakar rekayasa kontrol dan engenering Institut Teknologi Bandung, baru-baru ini, di Semarang, Jawa Tengah. Menurut Kusmayanto, Pasal 27 Undang-undang Kesehatan Nomor 23 mendefinisikan obat tradisional sebagai pengobatan di luar ilmu kedokteran atau keperawatan. Definisi ini membuat pengusaha jamu sulit meresepkan jamunya untuk pengobatan. Di sisi lain, obat tradisional asal Cina justru membanjiri pasar Indonesia tanpa pengawasan yang ketat. Padahal, impor obat Cina dapat menguras devisa negara. Untuk mengembangkan industri obat tradisional, pengusaha jamu akan bekerja sama dengan sejumlah perguruan tinggi (PT). Sebab, PT dinilai dapat meneliti mutu jamu dan tanaman bahan baku jamu. Hasil penelitiannya dapat dimanfaatkan untuk kepentingan masyarakat. Kusmayanto berharapa, kerja sama antara PT dan industri jamu dapat segera terwujud. Sebab, bila tidak ada kerja sama, Indonesia hanya menjadi penonton di negeri sendiri, tanpa bisa bersaing dengan obat impor.\",\n          \"Hari Ini, Dua Kubu yang Bertikai Bertemu ]. Kendati demikian, tim mediator dipimpin Menteri Koordinator Bidang Kesejahteraan Rakyat Jusuf Kalla beserta kelompok peninjau optimistis perundingan hari ini akan membuahkan hasil, yakni kesepakatan damai atau rekonsiliasi. Menurut rencana, hari ini diagendakan rapat pleno yang mempertemukan kedua kubu tersebut dengan tim mediator dan peninjau dengan tema : Menuju Damai. Merujuk pertemuan pendahuluan antara tim mediator dan peninjau, rapat pleno akan memprioritaskan dua buah agenda pembahasan [ baca : Pemerintah Berharap Konflik Poso Segera Berakhir ]. Pertama, desakan untuk segera menghentikan konflik yang berlangsung sejak 1998. Selain itu, para penengah akan melontarkan sejumlah langkah rekonsiliasi secara detail kepada dua kelompok yang bertikai tersebut. Untuk mendukung kedua upaya tersebut, tim mediator dan peninjau berusaha mencari titik temunya. Di sisi lain, kendati kedua kelompok berselisih itu sama-sama menginginkan perdamaian, sejumlah masalah teknis mengenai pelaksanaan rekonsiliasi diperkirakan bakal memperpanjang ajang pertemuan yang tengah mencari solusi penyelesaian pertikaian di Poso itu [ baca : Jusuf Kalla : Mereka Ingin Damai Tanpa Syarat ]. Soalnya, dalam pertemuan kemarin, secara terpisah kepada tim mediator, masing-masing kubu yang berseteru mengemukakan sejumlah keberatannya. Buktinya, mereka masih saja mempermasalahkan mengenai teknis upaya penghentian konflik dan rekonsiliasi yang akan disepakati serta disosialisasikan nanti. Misalnya, siapa yang harus terlebih dahulu meminta maaf.\",\n          \"DPR akan mencecar pemerintah soal mekanisme kenaikan tarif telepon yang bakal berlaku 10 Juni mendatang. Jika pemerintah tak bisa menjelaskan efektivitas kenaikan, DPR akan merekomendasikan penundaan harga baru telepon tadi. Demikian benang merah yang mencuat dalam rapat antara Komisi IV DPR dan Departemen Perhubungan dan Telekomunikasi di Gedung MPR/DPR Jakarta, Rabu (6/6). Dalam rapat tersebut, sejumlah anggota Komisi IV menilai, upaya pemerintah dan PT Telkom untuk mensosialisasikan kenaikan tarif telepon kurang serius dan terkesan tak transparan. Mereka juga mempertanyakan mekanisme baru kenaikan tarif, seperti pemberlakuan zona tunggal untuk kode area 021. Direktur Jenderal Pos dan Telekomunikasi Djamhari Sirat yang mewakili pemerintah mengatakan, akan meneruskan aspirasi tersebut. Dia berharap, sebelum meminta penundaan, DPR terlebih dahulu memberitahukan keinginan itu pada Menhubtel Budi M. Suyitno yang baru dilantik.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1819,\n        \"samples\": [\n          \"Obat tradisional impor asal Cina membanjiri pasar Indonesia. Pengusaha jamu di Tanah Air terancam akan menjadi penonton di negeri sendiri tanpa mampu bersaing.\",\n          \"Putaran kedua Pertemuan Malino yang mengagendakan babak akhir perundingan bakal berlangsung alot. Kedua kubu yang bertikai masih berselisih pendapat tentang teknis pelaksanaan rekonsiliasi nanti.\",\n          \"Komisi IV DPR akan merekomendasikan penundaan jika pemerintah tak bisa menjelaskan mekanisme kenaikan tarif telepon.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def inferencing_model(row):\n",
        "  st = time.time()\n",
        "  input_text = row['article']\n",
        "  inputs = tokenizer.encode(input_text,padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "  output = inference_model.to(\"cuda\").generate(inputs.to(\"cuda\"))\n",
        "  summary_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "  rt = time.time() - st\n",
        "  row['summary_ft_indobert'] = summary_text\n",
        "  row['rt_ft_indobert_seconds'] = rt\n",
        "  return row"
      ],
      "metadata": {
        "id": "ZQDBZ9vwroUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_used_inf = df_test_used.copy()"
      ],
      "metadata": {
        "id": "1QRBJhSFs3ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_used_inf = df_test_used_inf.apply(inferencing_model,axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "r6ha6cFbs7c1",
        "outputId": "b256b9d7-f4ab-4296-dc62-751f093ef9f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "r4w_YujGnHZ9",
        "outputId": "dade9c1f-58c0-45f9-f202-7c5955afdc9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             article  \\\n",
              "0  Terungkapnya jaringan pencurian kendaraan berm...   \n",
              "1  Permintaan pemerintah agar Sidang Paripurna DP...   \n",
              "2  Puluhan mahasiswa yang tergabung dalam Jaringa...   \n",
              "3  Badan Penyehatan Perbankan Nasional tetap mela...   \n",
              "4  Pemerintah terus berupaya memprakarsai islah n...   \n",
              "\n",
              "                                             summary  \\\n",
              "0  Petugas Polresta Bukit Tinggi meringkus komplo...   \n",
              "1  Badan Musyawarah DPR berharap pelaksanaan Sida...   \n",
              "2  Presiden Megawati Sukarnoputri diminta menguta...   \n",
              "3  Badan Penyehatan Perbankan Nasional tetap memp...   \n",
              "4  Pemerintah terus berupaya memprakarsai islah n...   \n",
              "\n",
              "                                 summary_ft_indobert  rt_ft_indobert_seconds  \n",
              "0  polisi berhasil membekuk dua tersangka pencuri...                0.335815  \n",
              "1  sidang paripurna dpr telah menyepakati jadwal ...                0.333158  \n",
              "2  puluhan mahasiswa makassar, sulsel, mendesak p...                0.323796  \n",
              "3  rencana perpanjangan obligasi daur ulang bank ...                0.317794  \n",
              "4  pemerintah terus berupaya memprakarsai islah n...                0.316813  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1da0aaf5-9e08-4d1a-a246-ac2f0db85bdf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>summary</th>\n",
              "      <th>summary_ft_indobert</th>\n",
              "      <th>rt_ft_indobert_seconds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Terungkapnya jaringan pencurian kendaraan berm...</td>\n",
              "      <td>Petugas Polresta Bukit Tinggi meringkus komplo...</td>\n",
              "      <td>polisi berhasil membekuk dua tersangka pencuri...</td>\n",
              "      <td>0.335815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Permintaan pemerintah agar Sidang Paripurna DP...</td>\n",
              "      <td>Badan Musyawarah DPR berharap pelaksanaan Sida...</td>\n",
              "      <td>sidang paripurna dpr telah menyepakati jadwal ...</td>\n",
              "      <td>0.333158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Puluhan mahasiswa yang tergabung dalam Jaringa...</td>\n",
              "      <td>Presiden Megawati Sukarnoputri diminta menguta...</td>\n",
              "      <td>puluhan mahasiswa makassar, sulsel, mendesak p...</td>\n",
              "      <td>0.323796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Badan Penyehatan Perbankan Nasional tetap mela...</td>\n",
              "      <td>Badan Penyehatan Perbankan Nasional tetap memp...</td>\n",
              "      <td>rencana perpanjangan obligasi daur ulang bank ...</td>\n",
              "      <td>0.317794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pemerintah terus berupaya memprakarsai islah n...</td>\n",
              "      <td>Pemerintah terus berupaya memprakarsai islah n...</td>\n",
              "      <td>pemerintah terus berupaya memprakarsai islah n...</td>\n",
              "      <td>0.316813</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1da0aaf5-9e08-4d1a-a246-ac2f0db85bdf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1da0aaf5-9e08-4d1a-a246-ac2f0db85bdf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1da0aaf5-9e08-4d1a-a246-ac2f0db85bdf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c5d6fb48-c19e-4767-871d-744328154e69\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c5d6fb48-c19e-4767-871d-744328154e69')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c5d6fb48-c19e-4767-871d-744328154e69 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test_used_inf",
              "summary": "{\n  \"name\": \"df_test_used_inf\",\n  \"rows\": 2000,\n  \"fields\": [\n    {\n      \"column\": \"article\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1819,\n        \"samples\": [\n          \"Pemerintah dinilai belum memperhatikan industri obat tradisional, khususnya jamu. Padahal, di Indonesia ada sepuluh ribu spesies tanaman yang dapat dijadikan bahan baku jamu.  Hal ini terbukti dengan belum disejajarkannya jamu dengan obat-obatan farmasi,  kata Kusmayanto Kadiman, pakar rekayasa kontrol dan engenering Institut Teknologi Bandung, baru-baru ini, di Semarang, Jawa Tengah. Menurut Kusmayanto, Pasal 27 Undang-undang Kesehatan Nomor 23 mendefinisikan obat tradisional sebagai pengobatan di luar ilmu kedokteran atau keperawatan. Definisi ini membuat pengusaha jamu sulit meresepkan jamunya untuk pengobatan. Di sisi lain, obat tradisional asal Cina justru membanjiri pasar Indonesia tanpa pengawasan yang ketat. Padahal, impor obat Cina dapat menguras devisa negara. Untuk mengembangkan industri obat tradisional, pengusaha jamu akan bekerja sama dengan sejumlah perguruan tinggi (PT). Sebab, PT dinilai dapat meneliti mutu jamu dan tanaman bahan baku jamu. Hasil penelitiannya dapat dimanfaatkan untuk kepentingan masyarakat. Kusmayanto berharapa, kerja sama antara PT dan industri jamu dapat segera terwujud. Sebab, bila tidak ada kerja sama, Indonesia hanya menjadi penonton di negeri sendiri, tanpa bisa bersaing dengan obat impor.\",\n          \"Hari Ini, Dua Kubu yang Bertikai Bertemu ]. Kendati demikian, tim mediator dipimpin Menteri Koordinator Bidang Kesejahteraan Rakyat Jusuf Kalla beserta kelompok peninjau optimistis perundingan hari ini akan membuahkan hasil, yakni kesepakatan damai atau rekonsiliasi. Menurut rencana, hari ini diagendakan rapat pleno yang mempertemukan kedua kubu tersebut dengan tim mediator dan peninjau dengan tema : Menuju Damai. Merujuk pertemuan pendahuluan antara tim mediator dan peninjau, rapat pleno akan memprioritaskan dua buah agenda pembahasan [ baca : Pemerintah Berharap Konflik Poso Segera Berakhir ]. Pertama, desakan untuk segera menghentikan konflik yang berlangsung sejak 1998. Selain itu, para penengah akan melontarkan sejumlah langkah rekonsiliasi secara detail kepada dua kelompok yang bertikai tersebut. Untuk mendukung kedua upaya tersebut, tim mediator dan peninjau berusaha mencari titik temunya. Di sisi lain, kendati kedua kelompok berselisih itu sama-sama menginginkan perdamaian, sejumlah masalah teknis mengenai pelaksanaan rekonsiliasi diperkirakan bakal memperpanjang ajang pertemuan yang tengah mencari solusi penyelesaian pertikaian di Poso itu [ baca : Jusuf Kalla : Mereka Ingin Damai Tanpa Syarat ]. Soalnya, dalam pertemuan kemarin, secara terpisah kepada tim mediator, masing-masing kubu yang berseteru mengemukakan sejumlah keberatannya. Buktinya, mereka masih saja mempermasalahkan mengenai teknis upaya penghentian konflik dan rekonsiliasi yang akan disepakati serta disosialisasikan nanti. Misalnya, siapa yang harus terlebih dahulu meminta maaf.\",\n          \"DPR akan mencecar pemerintah soal mekanisme kenaikan tarif telepon yang bakal berlaku 10 Juni mendatang. Jika pemerintah tak bisa menjelaskan efektivitas kenaikan, DPR akan merekomendasikan penundaan harga baru telepon tadi. Demikian benang merah yang mencuat dalam rapat antara Komisi IV DPR dan Departemen Perhubungan dan Telekomunikasi di Gedung MPR/DPR Jakarta, Rabu (6/6). Dalam rapat tersebut, sejumlah anggota Komisi IV menilai, upaya pemerintah dan PT Telkom untuk mensosialisasikan kenaikan tarif telepon kurang serius dan terkesan tak transparan. Mereka juga mempertanyakan mekanisme baru kenaikan tarif, seperti pemberlakuan zona tunggal untuk kode area 021. Direktur Jenderal Pos dan Telekomunikasi Djamhari Sirat yang mewakili pemerintah mengatakan, akan meneruskan aspirasi tersebut. Dia berharap, sebelum meminta penundaan, DPR terlebih dahulu memberitahukan keinginan itu pada Menhubtel Budi M. Suyitno yang baru dilantik.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1819,\n        \"samples\": [\n          \"Obat tradisional impor asal Cina membanjiri pasar Indonesia. Pengusaha jamu di Tanah Air terancam akan menjadi penonton di negeri sendiri tanpa mampu bersaing.\",\n          \"Putaran kedua Pertemuan Malino yang mengagendakan babak akhir perundingan bakal berlangsung alot. Kedua kubu yang bertikai masih berselisih pendapat tentang teknis pelaksanaan rekonsiliasi nanti.\",\n          \"Komisi IV DPR akan merekomendasikan penundaan jika pemerintah tak bisa menjelaskan mekanisme kenaikan tarif telepon.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary_ft_indobert\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1819,\n        \"samples\": [\n          \"pemerintah dinilai tak serius menangani industri obat tradisional. produk yang diekspor tak dapat bersaing dengan produk luar\",\n          \"rapat pleno yang dipimpin menko kesra jusuf kalla dan tim mediator ini akan memprioritaskan pembahasan materi rekonsiliasi.\",\n          \"pemerintah dan pt telkom diminta tak menjelaskan mekanisme kenaikan tarif baru telepon. dpr akan merekomendasikan penundaan kenaikan\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rt_ft_indobert_seconds\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011063564423218047,\n        \"min\": 0.2865133285522461,\n        \"max\": 0.395709753036499,\n        \"num_unique_values\": 1986,\n        \"samples\": [\n          0.3068211078643799,\n          0.3159177303314209,\n          0.31310105323791504\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 127
        }
      ],
      "source": [
        "df_test_used_inf.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "def evaluate_rouge(row):\n",
        "  results = rouge.compute(predictions=[row['summary_ft_indobert']], references=[row['summary']])\n",
        "  row['rouge1'] = results['rouge1']\n",
        "  row['rouge2'] = results['rouge2']\n",
        "  row['rougeL'] = results['rougeL']\n",
        "  row['rougeLsum'] = results['rougeLsum']\n",
        "  return row\n"
      ],
      "metadata": {
        "id": "cumQvyLz44fU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_used_inf = df_test_used_inf.apply(evaluate_rouge,axis=1)"
      ],
      "metadata": {
        "id": "OgzkA6ua7KLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_used_inf.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "1giz5QX47nix",
        "outputId": "31db4867-3528-477d-9a00-039b8be255c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             article  \\\n",
              "0  Terungkapnya jaringan pencurian kendaraan berm...   \n",
              "1  Permintaan pemerintah agar Sidang Paripurna DP...   \n",
              "2  Puluhan mahasiswa yang tergabung dalam Jaringa...   \n",
              "3  Badan Penyehatan Perbankan Nasional tetap mela...   \n",
              "4  Pemerintah terus berupaya memprakarsai islah n...   \n",
              "\n",
              "                                             summary  \\\n",
              "0  Petugas Polresta Bukit Tinggi meringkus komplo...   \n",
              "1  Badan Musyawarah DPR berharap pelaksanaan Sida...   \n",
              "2  Presiden Megawati Sukarnoputri diminta menguta...   \n",
              "3  Badan Penyehatan Perbankan Nasional tetap memp...   \n",
              "4  Pemerintah terus berupaya memprakarsai islah n...   \n",
              "\n",
              "                                 summary_ft_indobert  rt_ft_indobert_seconds  \\\n",
              "0  polisi berhasil membekuk dua tersangka pencuri...                0.335815   \n",
              "1  sidang paripurna dpr telah menyepakati jadwal ...                0.333158   \n",
              "2  puluhan mahasiswa makassar, sulsel, mendesak p...                0.323796   \n",
              "3  rencana perpanjangan obligasi daur ulang bank ...                0.317794   \n",
              "4  pemerintah terus berupaya memprakarsai islah n...                0.316813   \n",
              "\n",
              "     rouge1    rouge2    rougeL  rougeLsum  \n",
              "0  0.243902  0.153846  0.195122   0.195122  \n",
              "1  0.400000  0.157895  0.250000   0.250000  \n",
              "2  0.500000  0.333333  0.375000   0.375000  \n",
              "3  0.208333  0.086957  0.166667   0.166667  \n",
              "4  0.457143  0.363636  0.457143   0.457143  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dec35288-dd43-497c-be93-17dee358caea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>summary</th>\n",
              "      <th>summary_ft_indobert</th>\n",
              "      <th>rt_ft_indobert_seconds</th>\n",
              "      <th>rouge1</th>\n",
              "      <th>rouge2</th>\n",
              "      <th>rougeL</th>\n",
              "      <th>rougeLsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Terungkapnya jaringan pencurian kendaraan berm...</td>\n",
              "      <td>Petugas Polresta Bukit Tinggi meringkus komplo...</td>\n",
              "      <td>polisi berhasil membekuk dua tersangka pencuri...</td>\n",
              "      <td>0.335815</td>\n",
              "      <td>0.243902</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.195122</td>\n",
              "      <td>0.195122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Permintaan pemerintah agar Sidang Paripurna DP...</td>\n",
              "      <td>Badan Musyawarah DPR berharap pelaksanaan Sida...</td>\n",
              "      <td>sidang paripurna dpr telah menyepakati jadwal ...</td>\n",
              "      <td>0.333158</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Puluhan mahasiswa yang tergabung dalam Jaringa...</td>\n",
              "      <td>Presiden Megawati Sukarnoputri diminta menguta...</td>\n",
              "      <td>puluhan mahasiswa makassar, sulsel, mendesak p...</td>\n",
              "      <td>0.323796</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.375000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Badan Penyehatan Perbankan Nasional tetap mela...</td>\n",
              "      <td>Badan Penyehatan Perbankan Nasional tetap memp...</td>\n",
              "      <td>rencana perpanjangan obligasi daur ulang bank ...</td>\n",
              "      <td>0.317794</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.166667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pemerintah terus berupaya memprakarsai islah n...</td>\n",
              "      <td>Pemerintah terus berupaya memprakarsai islah n...</td>\n",
              "      <td>pemerintah terus berupaya memprakarsai islah n...</td>\n",
              "      <td>0.316813</td>\n",
              "      <td>0.457143</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.457143</td>\n",
              "      <td>0.457143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dec35288-dd43-497c-be93-17dee358caea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dec35288-dd43-497c-be93-17dee358caea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dec35288-dd43-497c-be93-17dee358caea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3ab2332b-270d-41b5-995a-7dda643efa93\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3ab2332b-270d-41b5-995a-7dda643efa93')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3ab2332b-270d-41b5-995a-7dda643efa93 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test_used_inf",
              "summary": "{\n  \"name\": \"df_test_used_inf\",\n  \"rows\": 2000,\n  \"fields\": [\n    {\n      \"column\": \"article\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1819,\n        \"samples\": [\n          \"Pemerintah dinilai belum memperhatikan industri obat tradisional, khususnya jamu. Padahal, di Indonesia ada sepuluh ribu spesies tanaman yang dapat dijadikan bahan baku jamu.  Hal ini terbukti dengan belum disejajarkannya jamu dengan obat-obatan farmasi,  kata Kusmayanto Kadiman, pakar rekayasa kontrol dan engenering Institut Teknologi Bandung, baru-baru ini, di Semarang, Jawa Tengah. Menurut Kusmayanto, Pasal 27 Undang-undang Kesehatan Nomor 23 mendefinisikan obat tradisional sebagai pengobatan di luar ilmu kedokteran atau keperawatan. Definisi ini membuat pengusaha jamu sulit meresepkan jamunya untuk pengobatan. Di sisi lain, obat tradisional asal Cina justru membanjiri pasar Indonesia tanpa pengawasan yang ketat. Padahal, impor obat Cina dapat menguras devisa negara. Untuk mengembangkan industri obat tradisional, pengusaha jamu akan bekerja sama dengan sejumlah perguruan tinggi (PT). Sebab, PT dinilai dapat meneliti mutu jamu dan tanaman bahan baku jamu. Hasil penelitiannya dapat dimanfaatkan untuk kepentingan masyarakat. Kusmayanto berharapa, kerja sama antara PT dan industri jamu dapat segera terwujud. Sebab, bila tidak ada kerja sama, Indonesia hanya menjadi penonton di negeri sendiri, tanpa bisa bersaing dengan obat impor.\",\n          \"Hari Ini, Dua Kubu yang Bertikai Bertemu ]. Kendati demikian, tim mediator dipimpin Menteri Koordinator Bidang Kesejahteraan Rakyat Jusuf Kalla beserta kelompok peninjau optimistis perundingan hari ini akan membuahkan hasil, yakni kesepakatan damai atau rekonsiliasi. Menurut rencana, hari ini diagendakan rapat pleno yang mempertemukan kedua kubu tersebut dengan tim mediator dan peninjau dengan tema : Menuju Damai. Merujuk pertemuan pendahuluan antara tim mediator dan peninjau, rapat pleno akan memprioritaskan dua buah agenda pembahasan [ baca : Pemerintah Berharap Konflik Poso Segera Berakhir ]. Pertama, desakan untuk segera menghentikan konflik yang berlangsung sejak 1998. Selain itu, para penengah akan melontarkan sejumlah langkah rekonsiliasi secara detail kepada dua kelompok yang bertikai tersebut. Untuk mendukung kedua upaya tersebut, tim mediator dan peninjau berusaha mencari titik temunya. Di sisi lain, kendati kedua kelompok berselisih itu sama-sama menginginkan perdamaian, sejumlah masalah teknis mengenai pelaksanaan rekonsiliasi diperkirakan bakal memperpanjang ajang pertemuan yang tengah mencari solusi penyelesaian pertikaian di Poso itu [ baca : Jusuf Kalla : Mereka Ingin Damai Tanpa Syarat ]. Soalnya, dalam pertemuan kemarin, secara terpisah kepada tim mediator, masing-masing kubu yang berseteru mengemukakan sejumlah keberatannya. Buktinya, mereka masih saja mempermasalahkan mengenai teknis upaya penghentian konflik dan rekonsiliasi yang akan disepakati serta disosialisasikan nanti. Misalnya, siapa yang harus terlebih dahulu meminta maaf.\",\n          \"DPR akan mencecar pemerintah soal mekanisme kenaikan tarif telepon yang bakal berlaku 10 Juni mendatang. Jika pemerintah tak bisa menjelaskan efektivitas kenaikan, DPR akan merekomendasikan penundaan harga baru telepon tadi. Demikian benang merah yang mencuat dalam rapat antara Komisi IV DPR dan Departemen Perhubungan dan Telekomunikasi di Gedung MPR/DPR Jakarta, Rabu (6/6). Dalam rapat tersebut, sejumlah anggota Komisi IV menilai, upaya pemerintah dan PT Telkom untuk mensosialisasikan kenaikan tarif telepon kurang serius dan terkesan tak transparan. Mereka juga mempertanyakan mekanisme baru kenaikan tarif, seperti pemberlakuan zona tunggal untuk kode area 021. Direktur Jenderal Pos dan Telekomunikasi Djamhari Sirat yang mewakili pemerintah mengatakan, akan meneruskan aspirasi tersebut. Dia berharap, sebelum meminta penundaan, DPR terlebih dahulu memberitahukan keinginan itu pada Menhubtel Budi M. Suyitno yang baru dilantik.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1819,\n        \"samples\": [\n          \"Obat tradisional impor asal Cina membanjiri pasar Indonesia. Pengusaha jamu di Tanah Air terancam akan menjadi penonton di negeri sendiri tanpa mampu bersaing.\",\n          \"Putaran kedua Pertemuan Malino yang mengagendakan babak akhir perundingan bakal berlangsung alot. Kedua kubu yang bertikai masih berselisih pendapat tentang teknis pelaksanaan rekonsiliasi nanti.\",\n          \"Komisi IV DPR akan merekomendasikan penundaan jika pemerintah tak bisa menjelaskan mekanisme kenaikan tarif telepon.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary_ft_indobert\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1819,\n        \"samples\": [\n          \"pemerintah dinilai tak serius menangani industri obat tradisional. produk yang diekspor tak dapat bersaing dengan produk luar\",\n          \"rapat pleno yang dipimpin menko kesra jusuf kalla dan tim mediator ini akan memprioritaskan pembahasan materi rekonsiliasi.\",\n          \"pemerintah dan pt telkom diminta tak menjelaskan mekanisme kenaikan tarif baru telepon. dpr akan merekomendasikan penundaan kenaikan\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rt_ft_indobert_seconds\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011063564423218047,\n        \"min\": 0.2865133285522461,\n        \"max\": 0.395709753036499,\n        \"num_unique_values\": 1986,\n        \"samples\": [\n          0.3068211078643799,\n          0.3159177303314209,\n          0.31310105323791504\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13618505452912544,\n        \"min\": 0.0,\n        \"max\": 0.7804878048780487,\n        \"num_unique_values\": 343,\n        \"samples\": [\n          0.372093023255814,\n          0.6363636363636364,\n          0.21621621621621623\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12136447524677735,\n        \"min\": 0.0,\n        \"max\": 0.6666666666666667,\n        \"num_unique_values\": 266,\n        \"samples\": [\n          0.3414634146341463,\n          0.45,\n          0.37837837837837834\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rougeL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12848311324625536,\n        \"min\": 0.0,\n        \"max\": 0.7804878048780487,\n        \"num_unique_values\": 333,\n        \"samples\": [\n          0.4,\n          0.4516129032258065,\n          0.39024390243902435\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rougeLsum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12848311324625536,\n        \"min\": 0.0,\n        \"max\": 0.7804878048780487,\n        \"num_unique_values\": 333,\n        \"samples\": [\n          0.4,\n          0.4516129032258065,\n          0.39024390243902435\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "n = random.randint(1,len(df_test_used_inf)-1)\n",
        "{'article':df_test_used_inf.loc[n]['article'],\n",
        "'summary':df_test_used_inf.loc[n]['summary'],\n",
        "'summary_ft_indobert':df_test_used_inf.loc[n]['summary_ft_indobert'],\n",
        "'rt_ft_indobert_seconds':df_test_used_inf.loc[n]['rt_ft_indobert_seconds'],\n",
        "'rouge1':df_test_used_inf.loc[n]['rouge1'],\n",
        "'rouge2':df_test_used_inf.loc[n]['rouge2'],\n",
        "'rougeL':df_test_used_inf.loc[n]['rougeL'],\n",
        "'rougeLsum':df_test_used_inf.loc[n]['rougeLsum']}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnGJSXHc_Rbs",
        "outputId": "d48a8c81-5d45-4154-8ecc-1ebed26576c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'article': 'Majelis Ulama Indonesia mendesak pemerintah membekukan sementara hubungan diplomatik dengan Amerika Serikat. Pernyataan itu disampaikan Sekretaris Umum MUI Dien Syamsudin yang membacakan sikap Forum Ukhuwah Islamiah, Senin (8/10) di Masjid Istiqlal, Jakarta. Dien mengatakan tanggapan terhadap serangan AS Ahad (7/10) silam itu ditujukan kepada Perserikatan Bangsa Bangsa, pemerintah Indonesia, dan seluruh umat Islam di dunia. Forum mendesak PBB untuk menghentikan serangan itu. MUI juga menilai AS harus dikenakan sanksi karena dianggap melanggar hukum internasional dan Hak Asasi Manusia. Pada kesempatan yang sama, Panglima Perang Laskar Jihad Jafar Umar Thalib menyatakan telah menyiapkan 10 ribu pasukan untuk dikirim ke Afghanistan. Hingga saat ini, kelompoknya menyiapkan dan melakukan rekrutmen bagi mereka yang hendak dikirim ke Afghanistan. Tapi Jafar tidak menyebutkan waktu pasukan tersebut akan diberangkatkan.',\n",
              " 'summary': 'Pemerintah Indonesia didesak memutuskan hubungan diplomatik dengan Amerika. Sebanyak 10 ribu laskar jihad siap dikirim ke Afghanistan.',\n",
              " 'summary_ft_indobert': 'forum ulama indonesia mendesak pemerintah membekukan sementara hubungan diplomatik dengan amerika serikat. forum ini juga mendesak pbb',\n",
              " 'rt_ft_indobert_seconds': 1.1543898582458496,\n",
              " 'rouge1': 0.35294117647058826,\n",
              " 'rouge2': 0.1875,\n",
              " 'rougeL': 0.29411764705882354,\n",
              " 'rougeLsum': 0.29411764705882354}"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "n = random.randint(1,len(df_test_used_inf)-1)\n",
        "{'article':df_test_used_inf.loc[n]['article'],\n",
        "'summary':df_test_used_inf.loc[n]['summary'],\n",
        "'summary_ft_indobert':df_test_used_inf.loc[n]['summary_ft_indobert'],\n",
        "'rt_ft_indobert_seconds':df_test_used_inf.loc[n]['rt_ft_indobert_seconds'],\n",
        "'rouge1':df_test_used_inf.loc[n]['rouge1'],\n",
        "'rouge2':df_test_used_inf.loc[n]['rouge2'],\n",
        "'rougeL':df_test_used_inf.loc[n]['rougeL'],\n",
        "'rougeLsum':df_test_used_inf.loc[n]['rougeLsum']}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-j4-kSmADH8",
        "outputId": "95df18ee-5f30-4546-9b09-e6e99dac1377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'article': 'Kepala Pusat Laboratorium Forensik Polri Brigadir Jenderal Polisi M Hamim Suryaamidjaya mengungkapkan bahan peledak pada Plaza Atrium Senen, Jakarta Pusat, menggunakan trinitrotulene dengan tiga detonator yang memiliki daya ledak tinggi.  Ledakan itu adalah bom mobil yang ditaruh di dalamnya. Tujuannya untuk meneror masyarakat,  kata dia kepada Indiarto Priadi di Studio SCTV, Senin (24/9) petang. Menurut Hamim, jenis bom ini terakhir digunakan pada ledakan menjelang malam Natal 2000. Petunjuk lain yang diperoleh adalah mobil pembawa bom itu bekas milik Tengku Ismuhadi, terpidana pengeboman Gedung Bursa Efek Jakarta. Hal yang menarik yaitu timer bom dari jam dinding tersimpan di jok belakang mobil. Jam berukuran besar itu dirangkaikan dengan kabel ke aki yang dihubungkan ke bagasi dan bagian bawah jok depan. Dia memperkirakan bom rangkaian itu dibuat dengan biaya yang relatif murah.  Saya bertangung jawab pada tempat kejadian dan analisa bahan peledak. Saya tak punya kewenangan mengidentifikasi pelaku dan mengkaitkannya dengan peristiwa-peristiwa silam,  kata dia. Sedangkan bekas Kepala Badan Koordinasi Intelijen Negara Letnan Jenderal TNI (purnawirawan) Z.A. Maulani mengatakan kepolisian bisa menemukan pelaku dengan berbagai petunjuk yang diperoleh. Polisi, kata Maulani, bisa menganalisa mengapa Atrium Senen hingga tiga kali menjadi sasaran peledakan bom. Menurut Maulani, polisi bisa mencari cara-cara pembuatan bom dan kesenangan pelaku untuk menyerang tempat tertentu.  Biasanya kelompok yang sama menyerang tempat-tempat dengan ciri sama,  kata dia. Penggunaan TNT sebagai bahan peledak juga menjadi petunjuk lain karena benda itu bukan barang yang bisa diperjualbelikan secara bebas di masyarakat. Bekas Sekretaris Wakil Presiden itu mengatakan penempatan bom rakitan di kendaraan bermotor bertujuan menebar teror ketakutan pada masyarakat setempat. Orang kepercayaan mantan Presiden Habibie itu mengatakan sebagai bekas intelijen, dia tak memiliki kewenangan untuk mengenali pelaku karena tak memiliki data-data dan fakta. Ketua Keluarga Besar Alumni Pelajar Islam Indonesia (PII) itu memperkirakan pelaku peristiwa itu bisa berasal dari kelompok pelaku peledakan sebelumnya atau kelompok lain yang menunggangi. Maulani menegaskan Polri harus mampu mengungkapkan kasus itu agar menumbuhkan kepercayaan masyarakat dan memberikan ketenangan.',\n",
              " 'summary': 'Tersangka pengeboman Plaza Atrium menggunakan bahan peledak yang berdaya ledak tinggi. Kelompok pelaku bisa berasal dari grup yang sama atau hanya sekedar membonceng.',\n",
              " 'summary_ft_indobert': 'bahan peledak itu berasal dari plaza atrium senen, jakpus. polisi menduga peledakan bom dengan cara meledakkan',\n",
              " 'rt_ft_indobert_seconds': 1.3833167552947998,\n",
              " 'rouge1': 0.30769230769230765,\n",
              " 'rouge2': 0.16216216216216214,\n",
              " 'rougeL': 0.20512820512820512,\n",
              " 'rougeLsum': 0.20512820512820512}"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "n = random.randint(1,len(df_test_used_inf)-1)\n",
        "{'article':df_test_used_inf.loc[n]['article'],\n",
        "'summary':df_test_used_inf.loc[n]['summary'],\n",
        "'summary_ft_indobert':df_test_used_inf.loc[n]['summary_ft_indobert'],\n",
        "'rt_ft_indobert_seconds':df_test_used_inf.loc[n]['rt_ft_indobert_seconds'],\n",
        "'rouge1':df_test_used_inf.loc[n]['rouge1'],\n",
        "'rouge2':df_test_used_inf.loc[n]['rouge2'],\n",
        "'rougeL':df_test_used_inf.loc[n]['rougeL'],\n",
        "'rougeLsum':df_test_used_inf.loc[n]['rougeLsum']}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3t_JZ5HyADor",
        "outputId": "34f6c325-977f-4e7b-a6c6-ab9dddc14ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'article': 'Pemerintah belum menemukan titik temu dalam menentukan jumlah anggaran untuk Kredit Perumahan Rakyat (KPR). Pasalnya, usulan antara Menteri Keuangan Boediono dan Menteri Pemukiman Prasarana Wilayah Soenarno masih berseberangan. Karena itu, persoalan realisasi anggaran KPR tahun 2001 menjadi kabur dan berlarut-larut. Demikian Direktur Jenderal Anggaran dan Keuangan Darmin Nasution, di sela-sela dengar pendapat antara Departemen Keuangan dan Komisi IX DPR, di Jakarta, Senin (22/10). Menurut Darmin, Menkeu Boediono menginginkan jumlah subsidi KPR diperkecil karena anggaran negara terbatas. Sebaliknya Seonarno mengajukan anggaran untuk rumah sederhana dan rumah sangat sederhana seluruhnya dapat direalisasikan pemerintah. Sayangnya, ketika SCTV meminta konfirmasi, Menkeu Boediono enggan menjawab pertanyaan tersebut. Sebelumnya, Menkimpraswil Soenarno pernah menjanjikan subsidi KPR senilai Rp 961 miliar untuk membangun 80 ribu RS dan RSS. Soenarno merencanakan akan mengucurkan dana itu pada September 2001. Namun, hingga kini janji pemerintah tersebut tak kunjung terealisasi. Menghadapi janji kosong pemerintah, Bank Tabungan Negara malah telah menghentikan dana talangannya sejak Mei silam. Sebab, pemerintah belum mengganti anggaran yang sudah dikucurkan BTN senilai Rp 142 miliar.',\n",
              " 'summary': 'Penghitungan jumlah subsidi untuk kredit perumahan rakyat masih kabur dan berlarut-larut. Menkimpraswil Soenarno berjanji bakal mengucurkan KPR senilai Rp 961 miliar.',\n",
              " 'summary_ft_indobert': 'usulan subsidi kpr untuk perumahan rakyat masih menjadi perdebatan. pemerintah diminta memperjelas jumlah subsidi kpr',\n",
              " 'rt_ft_indobert_seconds': 0.9651563167572021,\n",
              " 'rouge1': 0.3783783783783784,\n",
              " 'rouge2': 0.17142857142857143,\n",
              " 'rougeL': 0.3243243243243243,\n",
              " 'rougeLsum': 0.3243243243243243}"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rt_mean = df_test_used_inf['rt_ft_indobert_seconds'].mean()\n",
        "rt_std = df_test_used_inf['rt_ft_indobert_seconds'].std()\n",
        "rouge1_mean = df_test_used_inf['rouge1'].mean()\n",
        "rouge1_std = df_test_used_inf['rouge1'].std()\n",
        "rouge2_mean = df_test_used_inf['rouge2'].mean()\n",
        "rouge2_std = df_test_used_inf['rouge2'].std()\n",
        "rougeL_mean =  df_test_used_inf['rougeL'].mean()\n",
        "rougeL_std\t = df_test_used_inf['rougeL'].std()\n",
        "rougeLsum_mean = df_test_used_inf['rougeLsum'].mean()\n",
        "rougeLsum_std = df_test_used_inf['rougeLsum'].std()\n",
        "\n",
        "evaluation_str = f\"\"\"\n",
        "[Model Evaluation: Fine Tuned Pre-Trained Model Indobert-Base-Uncased]\n",
        "Runtime : {rt_mean:.2f}s (+/- {rt_std:.2f}s)\n",
        "Rouge1 : {rouge1_mean:.2f} (+/- {rouge1_std:.2f})\n",
        "Rouge2 : {rouge2_mean:.2f} (+/- {rouge2_std:.2f})\n",
        "RougeL : {rougeL_mean:.2f} (+/- {rougeL_std:.2f})\n",
        "RougeLsum : {rougeLsum_mean:.2f} (+/- {rougeLsum_std:.2f})\n",
        "\"\"\"\n",
        "print(evaluation_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8OmvcWl88YM",
        "outputId": "147339fa-8011-4e56-db42-436fa8ed3574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Model Evaluation: Fine Tuned Pre-Trained Model Indobert-Base-Uncased]\n",
            "Runtime : 0.31s (+/- 0.01s)\n",
            "Rouge1 : 0.33 (+/- 0.14)\n",
            "Rouge2 : 0.15 (+/- 0.12)\n",
            "RougeL : 0.28 (+/- 0.13)\n",
            "RougeLsum : 0.28 (+/- 0.13)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Future Works"
      ],
      "metadata": {
        "id": "WRcfP2QAAWBY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the performance evaluation of Fine Tuned Pre-Trained Model Indobert-base-uncased, it shown the\n",
        "- Rouge1 : 0.33 (+/- 0.14)\n",
        "- Rouge2 : 0.15 (+/- 0.12)\n",
        "- RougeL : 0.28 (+/- 0.13)\n",
        "- RougeLsum : 0.28 (+/- 0.13) <br>\n",
        "\n",
        "with average inferencing runtime is 1.06s (+/- 0.15s). This result relatively low for summarization compare with original Pre-Trained model which has Rouge1/Rouge2/RougeL is 69.93/62.86/69.21 [source](https://huggingface.co/indolem/indobert-base-uncased). This might caused by number our training data that only 35,000. So, I recommended to increase the number of data training.\n",
        "<br><br>\n",
        "Besides, we could also explore with others Pre-Trained model like\n",
        "- cahya/bert2bert-indonesian-summarization\n",
        "- cahya/t5-base-indonesian-summarization-cased\n",
        "- cahya/bert2gpt-indonesian-summarization\n",
        "- more..."
      ],
      "metadata": {
        "id": "ZkuYyjI8AZL9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQN467MTP1Hx"
      },
      "source": [
        "## Fine Tuning: cahya/bert2bert-indonesian-summarization [ON PROGRESS]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xqk9uPmMP7Rr"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, EncoderDecoderModel\n",
        "\n",
        "model_checkpoint = \"cahya/bert2bert-indonesian-summarization\"\n",
        "tokenizer = BertTokenizer.from_pretrained(\"cahya/bert2bert-indonesian-summarization\")\n",
        "tokenizer.bos_token = tokenizer.cls_token\n",
        "tokenizer.eos_token = tokenizer.sep_token\n",
        "\n",
        "# model = EncoderDecoderModel.from_pretrained(\"cahya/bert2bert-indonesian-summarization\")\n",
        "from transformers import AutoModelForSeq2SeqLM\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piygtTfEdu7k"
      },
      "outputs": [],
      "source": [
        "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "model.config.vocab_size = model.config.encoder.vocab_size\n",
        "\n",
        "model.config.encoder.max_length = 512\n",
        "model.config.decoder.max_length = 128\n",
        "model.config.decoder.min_length = 13\n",
        "# model.config.length_penalty = 2.0\n",
        "model.config.early_stopping = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BS8csLf6P8VA",
        "outputId": "53eedfc2-fd1c-472d-a6ca-ebad1351b640"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ribuan kades dan perangkat desa di nganjuk berunjuk rasa ke kantor bupati, menuntut pemberian gaji pokok sebesar upah minimum kabupaten. mereka mengancam akan menduduki pendopo kabupaten jika bupati tidak memenuhi tuntutan mereka.\n"
          ]
        }
      ],
      "source": [
        "# Try Inferencing Model (Before Fine tuning)\n",
        "inputs = tokenizer.encode(datasets['train'][42]['article'],return_tensors='pt')\n",
        "output = model.generate(inputs)\n",
        "summary_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(summary_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "6ebbd1059e3d4b41acb2d2373b19a7af",
            "b17feab9bc69468495776a737ca575d1",
            "5462b1b99710466cb59d132612bfc872",
            "d87317fc29a04516a25897f7d483c468",
            "5785961c657f44439f6f0b2f54d6a764",
            "bd5daf7e31474087a95c70ba33b5a40d",
            "8c99e5ff4b984a7cb395914981456a33",
            "07e5ee3574eb40579dfee7c9dee812c4",
            "db996a4601c248f9a103b3d0756cda78",
            "0ee57a6eaf3f4debaeb44f917df321bb",
            "3eb4b66a5b324973a64ea2a57aef6a33",
            "49a24352c5ee45f58c2f5002451cfe5f",
            "bae11f85f2634fda93cee420996bc332",
            "ba58d631ff8c46b792caa722482c5168",
            "70802b1b23e44fd19edee464ee5e4a70",
            "dc5de4a1303b4e29a6c37628b4841a7a",
            "37cab3be5f1843998d798536c60afecd",
            "49f18819f72d40268967d44716c2b354",
            "2d63f111548245f8a697c7b12a22c232",
            "3a28c3dff0b74e849c1a618f7c2d0a46",
            "e679f738070a46b0835bc33751a58490",
            "c29f91353718421487bb4892ed31dec8",
            "7655f7fba5794b33a4834c84284d8b2a",
            "a0cb958921da456a9374308203ad5f03",
            "140a8c34733f4f9cb104cc41d2c5c501",
            "c64a291ffd43491aa45ee71c28dd1010",
            "af95ba59189545059660df0d8769a30b",
            "5aef22247eb94edd80a5ff1769cb1227",
            "16622acd3b454aea981cebbf76d4f63d",
            "0e18e3853ba94b83bf6e0bd64e6529e6",
            "339d0ef79bf4484baa4601f87bf481b6",
            "a2d43ead7656449ab6617ab4003e94a0",
            "2df6358818d5472598f30e6e2dd3deee"
          ]
        },
        "id": "0MDxjeeHQjjf",
        "outputId": "f05b2a37-4d1b-4a62-cb32-38cc1581b1c6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ebbd1059e3d4b41acb2d2373b19a7af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/35000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49a24352c5ee45f58c2f5002451cfe5f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7655f7fba5794b33a4834c84284d8b2a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "max_input_length = 512\n",
        "max_target_length = 128\n",
        "\n",
        "def tokenize_function(text):\n",
        "    model_inputs = tokenizer(\n",
        "        text['article'],\n",
        "        max_length=max_input_length,\n",
        "        truncation=True,\n",
        "    )\n",
        "\n",
        "    labels = tokenizer(\n",
        "        text['summary'], max_length=max_target_length, truncation=True\n",
        "    )\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "tokenized_datasets = datasets.map(tokenize_function, batched=True, num_proc=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D98y3DnhQsRi",
        "outputId": "a9128d4c-4795-474d-8308-d4f5eaf27cd8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import evaluate\n",
        "from nltk.tokenize import sent_tokenize\n",
        "rouge_score = evaluate.load(\"rouge\")\n",
        "nltk.download('punkt')\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    # Decode generated summaries into text\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    print(\"decoded_preds\",decoded_preds)\n",
        "    # Replace -100 in the labels as we can't decode them\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    # Decode reference summaries into text\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    print(\"decoded_labels\",decoded_labels)\n",
        "    # ROUGE expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "    # Compute ROUGE scores\n",
        "    result = rouge_score.compute(\n",
        "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
        "    )\n",
        "    return {k: round(v, 4) for k, v in result.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZJ1e2jNNSUvC",
        "outputId": "f2573292-c5e0-4607-8243-88794aa8b3bb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cahya/bert2bert-indonesian-summarization'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUEq-LCTSOKZ"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRvm5ARVSZcG"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Seq2SeqTrainingArguments\n",
        "\n",
        "# logging_steps = len(tokenized_datasets[\"train\"]) // batch_size\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    output_dir=f\"{model_name}-checkpoint\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    gradient_accumulation_steps=1,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=8,\n",
        "    warmup_steps=5,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy='epoch',\n",
        "    load_best_model_at_end = True,\n",
        "    # save_total_limit=3,                      # Limit the maximum number of checkpoint saved during training\n",
        "    # predict_with_generate=True,              # To indicate that we should generate summaries during evaluation for computing ROUGE scores\n",
        "    # logging_steps=logging_steps,             # Show the training loss with every epoch\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfbc7gV3SfJ0"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, Seq2SeqTrainer,EarlyStoppingCallback\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    # compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "eaM_Qq-Ve0mn",
        "outputId": "d95b401e-4b63-4ba8-e98b-e2ee719cc084"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 01:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 2.8227956295013428,\n",
              " 'eval_runtime': 63.3023,\n",
              " 'eval_samples_per_second': 31.594,\n",
              " 'eval_steps_per_second': 3.949}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# try the trainer, to make sure we do not face error during training\n",
        "trainer.evaluate(tokenized_datasets['test']) # before training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "2yvZqJ8hSjuW",
        "outputId": "454e6d61-eca4-4cd8-96e8-d4aae336acad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8411' max='35000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 8411/35000 2:16:43 < 7:12:19, 1.03 it/s, Epoch 1.92/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.755600</td>\n",
              "      <td>2.443204</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 40, 'min_length': 20, 'early_stopping': True, 'num_beams': 10, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9246' max='35000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 9246/35000 2:31:29 < 7:02:03, 1.02 it/s, Epoch 2.11/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.755600</td>\n",
              "      <td>2.443204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.557700</td>\n",
              "      <td>2.536770</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 40, 'min_length': 20, 'early_stopping': True, 'num_beams': 10, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "trainer.train() # do the training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iz2OVJGfSp6q",
        "outputId": "ec3f2051-4456-4d60-fa09-6e87414e4cb9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 40, 'min_length': 20, 'early_stopping': True, 'num_beams': 10, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}\n"
          ]
        }
      ],
      "source": [
        "trainer.save_model(\"./fine_tuned_bert2bert\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MytVVcKxgdEp"
      },
      "outputs": [],
      "source": [
        "bert2bert_loaded = AutoModelForSeq2SeqLM.from_pretrained(\"./fine_tuned_bert2bert\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I33d7Dp-hrMH",
        "outputId": "332d4a12-64e5-4903-e8bc-4c5c0119986e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ketiga warga australia ini mengaku bersalah dan menyampaikan rasa penyesalan yang mendalam. selain itu, mereka juga memohon kepada majelis hakim untuk tidak memvonis hukuman mati bagi terpidana mati.\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer.encode(datasets['train'][42]['articles'],return_tensors='pt')\n",
        "output = bert2bert_loaded.generate(inputs)\n",
        "summary_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(summary_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Eyk3rI1iIAj"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "def inference_summarization(row):\n",
        "  st = time.time()\n",
        "  text = row['articles']\n",
        "  inputs = tokenizer.encode(text,return_tensors='pt',max_length=512, truncation=True)\n",
        "  output = bert2bert_loaded.generate(inputs)\n",
        "  summary_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "  row['summary_ft_cahya-bert2bert'] = summary_text\n",
        "  rt = time.time() - st\n",
        "  row['rt_ft_cahya-bert2bert_seconds'] = rt\n",
        "  return row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Y9zUCHdhrIm"
      },
      "outputs": [],
      "source": [
        "df_inference_test = df_test_used.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiOuuoZSib6g"
      },
      "outputs": [],
      "source": [
        "df_inference_test = df_inference_test.apply(inference_summarization,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRph8IQ2iAvx"
      },
      "outputs": [],
      "source": [
        "df_inference_test.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5IfKomrGMu3"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, EncoderDecoderModel\n",
        "\n",
        "model_checkpoint = \"cahya/bert2bert-indonesian-summarization\"\n",
        "tokenizer = BertTokenizer.from_pretrained(\"cahya/bert2bert-indonesian-summarization\")\n",
        "tokenizer.bos_token = tokenizer.cls_token\n",
        "tokenizer.eos_token = tokenizer.sep_token\n",
        "\n",
        "\n",
        "from transformers import AutoModelForSeq2SeqLM\n",
        "inf_model = AutoModelForSeq2SeqLM.from_pretrained(\"./fine_tuned_bert2bert\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------"
      ],
      "metadata": {
        "id": "R8ivWeAn-lHm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULuHW-lGuh6s"
      },
      "source": [
        "## Fine Tuning: cahya/t5-base-indonesian-summarization-cased [ON PROGRESS]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaLPzP0Fukq0",
        "outputId": "d25d1097-8fa6-4dba-87b9-c78c33392da0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['articles', 'summary_ref'],\n",
              "        num_rows: 5000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['articles', 'summary_ref'],\n",
              "        num_rows: 500\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['articles', 'summary_ref'],\n",
              "        num_rows: 500\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "B9TUAwrZu8U2",
        "outputId": "05bdcd53-bd37-4c67-c57e-cedb72ac36ca"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10635475899c4a8d833c9b8c9066ff6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.07k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5dd3c7837a5b4e3aba7b1a841da01539",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/657 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e78ecd70180249e8aea5fb63cc04dc80",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/793k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "099784d57a0948f3a4a49db469d5ca59",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_checkpoint = \"cahya/t5-base-indonesian-summarization-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CkY2KvavMPz",
        "outputId": "3c788730-ed4b-4dc5-f9c3-8797d305dc46"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'articles': 'Jenazah Inspektur Satu Polisi Sugeng dimakamkan di kampung halamannya Desa Mayong, Kecamatan Bagor, Kabupaten Nganjuk, Jawa Timur, Rabu (27/4) siang. Sugeng bunuh diri setelah menembak Ajun Komisaris Polisi Ibrahim Gani, Kepala Satuan Samapta Kepolisian Resor Jombang, Jatim. Sebelum dikuburkan, jenazah lelaki berusia 41 tahun ini sempat diotopsi di ruang jenazah Rumah Sakit Umum Daerah Jombang. Jasad ayah beranak dua ini kemudian disemayamkan di rumah duka di Perumahan Priyo Jombang Indah selama 30 menit. Setibanya di rumah duka, Endang Purwadani, istri almarhum tampak shock dan tak kuasa menahan tangis. Sementara kondisi AKP Ibrahim Gani yang mengalami luka tembak di bagian dada makin kritis. Ibrahim yang sempat dirawat di Rumah Sakit Umum Daerah Jombang langsung dirujuk ke RS Bhayangkara. Kepala Polres Jombang Ajun Komisaris Besar Polisi Dwi Sigit menjelaskan, insiden diduga karena Sugeng yang sudah satu bulan dinonaktifkan karena sakit-sakitan ini stres. Pada saat kejadian, dia masuk ke ruangan Kasat Samapta dan merebut senjata Ibrahim serta menembak dua kali ke dada korban.',\n",
              " 'summary_ref': 'Anggota DPRD Kota Makassar, Sulsel, dianggap tak serius mengatasi perubahan trayek dari Mal Makassar ke Perumahan Bumi Tamalanrea Permai. Padahal, dua sopir sudah jadi korban trayek baru ini.'}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datasets['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aILMmoJvFXC",
        "outputId": "43ac0d17-87ac-4066-8c22-7b707cdae8f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': [3776, 16941, 641, 10365, 14, 7373, 2062, 14, 788, 379, 1405, 1729, 884, 9102, 157, 1447, 37, 4431, 10365, 30, 1623, 3003, 465, 14312, 591, 13, 15342, 3, 9032, 14, 102, 1630, 11560, 140, 659, 3180, 9102, 157, 1447, 163, 20, 3, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "['▁Anggota', '▁DPRD', '▁Kota', '▁Makassar', ',', '▁Sul', 'sel', ',', '▁dianggap', '▁tak', '▁serius', '▁mengatasi', '▁perubahan', '▁tra', 'y', 'ek', '▁dari', '▁Mal', '▁Makassar', '▁ke', '▁Perumahan', '▁Bumi', '▁T', 'amalan', 're', 'a', '▁Permai', '.', '▁Padahal', ',', '▁dua', '▁so', 'pir', '▁sudah', '▁jadi', '▁korban', '▁tra', 'y', 'ek', '▁baru', '▁ini', '.', '</s>']\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer(datasets['train'][0]['summary_ref'])\n",
        "print(inputs)\n",
        "inputs = tokenizer.convert_ids_to_tokens(inputs.input_ids)\n",
        "print(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "id": "IZU2zGwQvVEQ",
        "outputId": "80000591-57b4-45d3-9b31-6363f95faee3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fda883401b984a419fe0507857cfbf25",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68b7bc807500472c9743e080814adf0e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7004ac957a3e43b3bbad40c3a9376ec8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "max_input_length = 512\n",
        "max_target_length = 128\n",
        "\n",
        "def tokenize_function(text):\n",
        "    model_inputs = tokenizer(\n",
        "        text['articles'],\n",
        "        max_length=max_input_length,\n",
        "        truncation=True,\n",
        "    )\n",
        "\n",
        "    labels = tokenizer(\n",
        "        text['summary_ref'], max_length=max_target_length, truncation=True\n",
        "    )\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "tokenized_datasets = datasets.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryLby3qnv_4p",
        "outputId": "10a05ca2-292d-4f2d-cbdd-fb1ab584a064"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['articles', 'summary_ref', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 5000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['articles', 'summary_ref', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 500\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['articles', 'summary_ref', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 500\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDuZi-gLv7-G",
        "outputId": "22bfd0f2-55b5-486a-a1d1-b5d6228d2138"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'train': ['input_ids', 'attention_mask', 'labels'],\n",
              " 'validation': ['input_ids', 'attention_mask', 'labels'],\n",
              " 'test': ['input_ids', 'attention_mask', 'labels']}"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_datasets['train'] = tokenized_datasets['train'].remove_columns(datasets['train'].column_names)\n",
        "tokenized_datasets['validation'] = tokenized_datasets['validation'].remove_columns(datasets['validation'].column_names)\n",
        "tokenized_datasets['test'] = tokenized_datasets['test'].remove_columns(datasets['test'].column_names)\n",
        "\n",
        "tokenized_datasets.column_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCpRKPS9w3x1",
        "outputId": "fce78c9c-8fe0-45ac-d897-e34021d45c29"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 5000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 500\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 500\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxxGuW6tfN_e",
        "outputId": "ddb4e5e1-2cce-4bf6-c9bb-55a9f280ee70"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OE72H7f9xJHq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import evaluate\n",
        "rouge_score = evaluate.load(\"rouge\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    # Decode generated summaries into text\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    # Decode reference summaries into text\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    # ROUGE expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "    # Compute ROUGE scores\n",
        "    result = rouge_score.compute(\n",
        "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
        "    )\n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-57pE8Yve88m",
        "outputId": "3655ad00-c15e-45f0-b0c4-c09e7dc3ea9c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cahya/t5-base-indonesian-summarization-cased'"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "zSAYsSatxMQ8",
        "outputId": "16a0cae1-168e-4af7-8578-ec9cd261272e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef96b637b24b4f1e85c124ba3ebca28b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEH2fbRjxPqL"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "biTucYXBxRz2",
        "outputId": "2ec90a58-9f68-4611-de6f-ae55ebd524ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 18832, 140165,    563,  45698,    715,  39430,  34878,    266,   2179,\n",
              "         104224,    301, 158477,    502,    301,    259,  71379,    382,  26409,\n",
              "            647,  30945,   1797,   2836,    261,  37988,  53529,   8054,    723,\n",
              "            261,    412,  24595, 178687,   6092,    261,  17965,  39055,    261,\n",
              "          22883,    273,  41242,    275,  11991,    259, 131887,    260,   2179,\n",
              "         104224,    330,  79123,   5695,    259,  16496,    692, 167076,    298,\n",
              "          20735,  25734,  37085,  34878,    266,  41344,  21575,    266,    261,\n",
              "            412,  87646,  39430,    321,   4111,  52714,   1589, 148472,    321,\n",
              "          13712,    723,   2851,  49522,    261,   1480,   8770,    260,  73037,\n",
              "          13408, 118432,    502,    261,   8391, 140165,    259,  37226,    693,\n",
              "          15568,   5420,   4481,    854,    259,  51200,    301,    268,   1332,\n",
              "            522,    301,    259,  39003,   8391, 140165,    259,  28988,  66933,\n",
              "            270,   3048,    606,    431,  25062,   2851,  49522,    260,  17829,\n",
              "           1147,    259,  16079,    693,  11455,   8912,    854,    259,  20257,\n",
              "          41904,  11557,    282,    502,    301,   7413, 188371,    301,  31016,\n",
              "          28513,   4036,   1651,   2851,  49522,    563,  15391,  15133,    733,\n",
              "            259,  48756,    260,    746,  17373,    647,    301,   7413, 188371,\n",
              "            261,    642,   8298,  14614, 101573,    516,    261,    259,  58873,\n",
              "          23854, 175205,    259,    270,  24133,    259,  41082,    469,    756,\n",
              "            259,  28061,    692,  13407,  28276,    417,    260,    320,  28071,\n",
              "          26195,    522,    259,  68021,  41344,  21575,    266,    457,   1224,\n",
              "          11282, 101142,    400,  65137,    301,    259,  10775,  57533,  44046,\n",
              "          88209,    260,  41344,    457,    259,  51200,    301,  52847,    301,\n",
              "            259,  28988,  66933,    270,   3048,    606,    431,  25062,   2851,\n",
              "          49522,    259,  10761,  91217,   6092,    513,  17903,  22176,   5017,\n",
              "           8793,    260,    412,  87646,   7433,   2244,   2851,  49522,    298,\n",
              "          20735,  25734,  37085,    364,  35844,  34878,    266,    431,   3367,\n",
              "          31099,    503,  27667,  35225,    261,  21024,    272,    301,  73952,\n",
              "            259,   4367,   2179, 104224,    457,    259,   3697,   3047,   8709,\n",
              "            779,    444,  27627,    502,    259,   4367,  19569,    264,    263,\n",
              "         191650,    854,  27473,    260,  11281,   2941,  48447,  20761,    261,\n",
              "           1619,    259,   5762,    513,    259,    286,  43753,  73813,    270,\n",
              "           4111,  52714,    469,    416, 103056,    303, 126756,  41344,    259,\n",
              "           5204,    692, 167076,   8912,   5346,    513,  57533,    259,  63369,\n",
              "            260,      1,      0,      0,      0,      0,      0,      0,      0,\n",
              "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
              "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
              "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
              "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
              "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
              "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
              "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
              "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
              "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
              "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
              "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
              "              0,      0,      0,      0,      0,      0,      0,      0,      0],\n",
              "        [  8453,   7426,    305,    259, 120131,    261,    320,  70548,  39874,\n",
              "          16773,    506,    416,  24877,    502,  57650,  36151,    767,   8247,\n",
              "            269,  82999,  63703,  38570,    280,   9343,    298,  24588,   1760,\n",
              "           9722,    457,  26318,   5272,    579,    301,    393,    262,  10742,\n",
              "         116627,  16093,    261,    412,  24595,  59214, 114292,    270,    261,\n",
              "          15636,  64420,  45412,    260,  76583,  36151,    457,    416,  32290,\n",
              "            502,   8912,  63703,  68576,    457,    259,  33334,    854,  47920,\n",
              "          65483,    259,  16496,    259,  51200,    301,  32868,    502,    513,\n",
              "          30237,    603,  15956,    260,  76583,  36151,   3864,    854,    301,\n",
              "          98905,    502,    301,    393,    262,  10742, 116627,  16093,    303,\n",
              "          61233,  77412,    457,  42186, 131877,    847,    393,    262,  10742,\n",
              "          56682,    606,    301,  15636,  64420,    366,  41544,    260,   2491,\n",
              "            407,  23665,  38060,  24537,  63703,  68576,    457,    259,  33334,\n",
              "            261,    259,  19816,  68576,    259,  13648,    259,  77355,  81765,\n",
              "          19331,    457,   1224, 126655,    670,  12598,  16764,    314, 210929,\n",
              "           1456,  20273,    262,    301,    393,    262,  10742,   3653,    260,\n",
              "           8453,  54313,   1639,    259,   6418,  19715,  46258,    259,  19816,\n",
              "          68576,    513,   6382,  26318,   5272,    579,    260,  38893,    298,\n",
              "          24588,   1760,   9722,    693,  23133,   1085,  40727, 110379,    366,\n",
              "          75133,  37423,    314,    261,  13056,    581,  12534,    261,   8436,\n",
              "           1259,  40727, 110379,   5766, 171718,    259, 185650, 188825,    260,\n",
              "          38570,    280,  26318,   5272,    579,    259,  16496,    259, 182117,\n",
              "           4171,    542,  12530,   7463,    259,   4367,    651,   9622,    259,\n",
              "          48344,    260,    259,  10558,  28710, 109354,    854,    261,  27270,\n",
              "          63703,  68576,    693,   6950,    301,  33334,    502,  68576,    448,\n",
              "          25012,    260,    259,  16499,    261,    269,  82999,  63703,  68576,\n",
              "          15257,    261,    767,   5762,   4961, 100433,  31099,    503,  36238,\n",
              "            276,  13487,    261,    259,   4561,   2941,    854,    259,  14144,\n",
              "          47920,  16310,    491,  29775,    259,    267,  38570,    280,  43935,\n",
              "           5272,    579,    261,    746,  77157,    298,  39100,    447,  11359,\n",
              "            259,  10070,    312,  75797,    275,    478,  11289,    515, 138808,\n",
              "            271,    298,  39100,  68576,    457,    259,   6885,    301,  25029,\n",
              "            259,    267,   1025,  31099,    503,  36238,    276,  13487,    261,\n",
              "           4961, 100433,   1219,  67322,   2384,    261,    890,  18492,   8912,\n",
              "           1501,  42771,  20000,  15504,   6056,  61820,    492,    261,  20925,\n",
              "            259,  18252,   1872,    352,    260,  58031,    266,   5105,  20239,\n",
              "            261,    259,  71326,    263,   8912,   2303,   5703, 193101,    268,\n",
              "            261,    259,  10775,    259,  26762,   2840,  17408,    276,    298,\n",
              "            261,    259,  10775,    259,  26762,   3278,   8933,  25515,    261,\n",
              "            259,  75004,  67491,   4050,    746,  11497,  63703,  15257,    259,\n",
              "          14144,  13408,  17133, 127285,    263,    647,    298,  39100,  68576,\n",
              "            457,    259,  33334,    259,    267,   1025,  64567,    259, 174267,\n",
              "            261,    890,  18492,   3047,   1219,   1151, 145529,  19346,    523,\n",
              "            261,    259,  71326,    263,   3047,   1501,  12619,  38166,   1346,\n",
              "            261,    259,  10775,    259,  26762,   1872,    366,  89285,  76000,\n",
              "            372,    823,    261,    259,  10775,    259,  26762,   2303,   4557,\n",
              "          80665,    261,    259,  75004,    259, 146360,    260,    260,      1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[  2182,  26320,    431,  89994,  13762,   1221, 101967,    261,  11770,\n",
              "           2609,    261,    301,  20261,    756,    303,  16415,   1224,  28731,\n",
              "            393,  44328,   1912,  53774,   1085,   3915,   1221, 101967,    513,\n",
              "          31016,  28513,   1153,    711,    366,  85343,   3514, 149324,    266,\n",
              "            260,  11281,   6866,    261,   8912,  37835,    286,    259,   3697,\n",
              "           7812,    259,  63369,   1912,  53774,   5551,    854,    260,      1,\n",
              "           -100,   -100],\n",
              "        [   259, 129660, 209095,  47726,    286,  71875,  25000,  11281,    370,\n",
              "          34261,  27484,    261,    320, 201371,    261,    301,   3783,    259,\n",
              "           4367,  14016,    513,  15929,  97433,   5769,  31640,    259,  44493,\n",
              "            469,   5703,  22630,  35000,    280,    756,  93090,    263,    303,\n",
              "          71939,   3483,  18756,    259,  49859,    330,  88060,    303,  54558,\n",
              "            260,  66641,    416,  12665,  71875,  25000,  25921,    303,  61233,\n",
              "            260,      1]]), 'decoder_input_ids': tensor([[     0,   2182,  26320,    431,  89994,  13762,   1221, 101967,    261,\n",
              "          11770,   2609,    261,    301,  20261,    756,    303,  16415,   1224,\n",
              "          28731,    393,  44328,   1912,  53774,   1085,   3915,   1221, 101967,\n",
              "            513,  31016,  28513,   1153,    711,    366,  85343,   3514, 149324,\n",
              "            266,    260,  11281,   6866,    261,   8912,  37835,    286,    259,\n",
              "           3697,   7812,    259,  63369,   1912,  53774,   5551,    854,    260,\n",
              "              1,      0],\n",
              "        [     0,    259, 129660, 209095,  47726,    286,  71875,  25000,  11281,\n",
              "            370,  34261,  27484,    261,    320, 201371,    261,    301,   3783,\n",
              "            259,   4367,  14016,    513,  15929,  97433,   5769,  31640,    259,\n",
              "          44493,    469,   5703,  22630,  35000,    280,    756,  93090,    263,\n",
              "            303,  71939,   3483,  18756,    259,  49859,    330,  88060,    303,\n",
              "          54558,    260,  66641,    416,  12665,  71875,  25000,  25921,    303,\n",
              "          61233,    260]])}"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features = [tokenized_datasets[\"train\"][i] for i in range(2)]\n",
        "data_collator(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnXsT3_9xTin",
        "outputId": "f0de4246-5b6c-4fbd-f817-c0492401ee0c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "batch_size = 8\n",
        "num_train_epochs = 5\n",
        "\n",
        "logging_steps = len(tokenized_datasets[\"train\"]) // batch_size\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    output_dir=f\"{model_name}-finetuned\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=5.6e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    save_total_limit=3,                      # Limit the maximum number of checkpoint saved during training\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    predict_with_generate=True,              # To indicate that we should generate summaries during evaluation for computing ROUGE scores\n",
        "    logging_steps=logging_steps,             # Show the training loss with every epoch\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "nJdQXiK3wQtz",
        "outputId": "ee8ba83d-8297-4790-d6c7-992c19c6501b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='54' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  54/3125 00:27 < 27:11, 1.88 it/s, Epoch 0.08/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-3a869d6032c6>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./fine_tuned_mT5_IndoSum\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1884\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1885\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1886\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1887\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2219\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2220\u001b[0m                     \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_xla_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2221\u001b[0;31m                     \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2222\u001b[0m                 ):\n\u001b[1;32m   2223\u001b[0m                     \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.save_model(\"./fine_tuned_mT5_IndoSum\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jo1rNxW7xx55"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svhqfIV_ut70"
      },
      "source": [
        "## Fine Tuning: cahya/bert2gpt-indonesian-summarization [ON PROGRESS]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3W7t6p-PH2S"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import BertTokenizer, BertModel, EncoderDecoderModel, TrainingArguments, Trainer, DataCollatorForSeq2Seq, EarlyStoppingCallback\n",
        "import evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232,
          "referenced_widgets": [
            "7b5c74dde8f44b16b0a0ea8dcd187687",
            "31ef91b865654644b83685b74bc30adc",
            "27f2e565197d4c5ca8f09e381adc1d52",
            "1ffa4d5c90fd42cbb655b808d0a5f4a5",
            "8586dbac7a764577b9356d60e6dacce0"
          ]
        },
        "id": "oWS_ZlwccpbX",
        "outputId": "ffc44fad-3462-48ff-ba99-7aeff67e9fb2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b5c74dde8f44b16b0a0ea8dcd187687",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/62.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31ef91b865654644b83685b74bc30adc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/230k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27f2e565197d4c5ca8f09e381adc1d52",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ffa4d5c90fd42cbb655b808d0a5f4a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/4.26k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8586dbac7a764577b9356d60e6dacce0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.08G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import BertTokenizer, EncoderDecoderModel\n",
        "\n",
        "model_checkpoint = 'cahya/bert2gpt-indonesian-summarization'\n",
        "tokenizer = BertTokenizer.from_pretrained('cahya/bert2gpt-indonesian-summarization')\n",
        "tokenizer.bos_token = tokenizer.cls_token\n",
        "tokenizer.eos_token = tokenizer.sep_token\n",
        "\n",
        "model = EncoderDecoderModel.from_pretrained('cahya/bert2gpt-indonesian-summarization')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S021LbzHddmO"
      },
      "outputs": [],
      "source": [
        "# model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "# model.config.pad_token_id = tokenizer.pad_token_id\n",
        "# model.config.vocab_size = model.config.encoder.vocab_size\n",
        "\n",
        "# model.config.encoder.max_length = 512\n",
        "# model.config.decoder.max_length = 128\n",
        "# model.config.decoder.min_length = 12\n",
        "# model.config.length_penalty = 2.0\n",
        "# model.config.early_stopping = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDNSqdXZddec",
        "outputId": "d063214c-72f4-43b7-e761-85595ccf8255"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[article]: Sidang lanjutan kasus penyelundupan heroin dari Bali ke Asutralia dengan terpidana mati Tan Duc Thanh Nguyen, Si Yi Chen, serta Mattew James Norman digelar di Pengadilan Negeri Denpasar, Bali, Senin (25/6). Sidang diisi dengan pembacaan pembelaan yang ditulis dengan tangan [ baca : Tiga Anggota Kelompok \" Bali Nine \" Mengajukan PK ].Dalam pembelaannya, ketiga warga Australia ini mengaku bersalah dan menyampaikan rasa penyesalan yang mendalam. Selain itu, mereka juga memohon kepada majelis hakim untuk tidak memvonis hukuman mati agar bisa memiliki kesempatan untuk memperbaiki diri. Tim kuasa hukum ketiga terpidana juga meminta majelis hakim memberikan keringanan hukuman mengingat usia mereka yang masih muda.\n",
            "[summary ref]: Kompor gas berbahan sekam temuan Slamet Sulaiman bisa digunakan sebagai alternatif bahan bakar. Kompor ini biayanya jauh lebih murah dibanding bahan bakar minyak tanah atau elpiji.\n",
            "[summary generated]: sidang lanjutan kasus penyelundupan heroin dari bali ke asutralia digelar di pn denpasar, bali. mereka meminta majelis hakim untuk tidak memvonis hukuman mati agar bisa memiliki kesempatan memperbaiki diri.\n",
            "runtime 13.78s\n"
          ]
        }
      ],
      "source": [
        "# Try Inferencing Model (Before Fine tuning)\n",
        "import time\n",
        "st = time.time()\n",
        "text = datasets['train'][42]['articles']\n",
        "inputs = tokenizer.encode(text,return_tensors='pt')\n",
        "output = model.generate(inputs)\n",
        "summary_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "rt = time.time() - st\n",
        "print(\"[article]:\",text)\n",
        "print(\"[summary ref]:\",datasets['train'][42]['summary_ref'])\n",
        "print(\"[summary generated]:\",summary_text)\n",
        "print(f'runtime {rt:.2f}s')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65KmNVStdPj1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PgsSgV9E-fdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjqEiGcH1Xo0"
      },
      "source": [
        "---------"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "bQN467MTP1Hx",
        "ULuHW-lGuh6s",
        "svhqfIV_ut70"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07e5ee3574eb40579dfee7c9dee812c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e18e3853ba94b83bf6e0bd64e6529e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ee57a6eaf3f4debaeb44f917df321bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "140a8c34733f4f9cb104cc41d2c5c501": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e18e3853ba94b83bf6e0bd64e6529e6",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_339d0ef79bf4484baa4601f87bf481b6",
            "value": 2000
          }
        },
        "16622acd3b454aea981cebbf76d4f63d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d63f111548245f8a697c7b12a22c232": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2df6358818d5472598f30e6e2dd3deee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "339d0ef79bf4484baa4601f87bf481b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "37cab3be5f1843998d798536c60afecd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a28c3dff0b74e849c1a618f7c2d0a46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3eb4b66a5b324973a64ea2a57aef6a33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49a24352c5ee45f58c2f5002451cfe5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bae11f85f2634fda93cee420996bc332",
              "IPY_MODEL_ba58d631ff8c46b792caa722482c5168",
              "IPY_MODEL_70802b1b23e44fd19edee464ee5e4a70"
            ],
            "layout": "IPY_MODEL_dc5de4a1303b4e29a6c37628b4841a7a"
          }
        },
        "49f18819f72d40268967d44716c2b354": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5462b1b99710466cb59d132612bfc872": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07e5ee3574eb40579dfee7c9dee812c4",
            "max": 35000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db996a4601c248f9a103b3d0756cda78",
            "value": 35000
          }
        },
        "5785961c657f44439f6f0b2f54d6a764": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5aef22247eb94edd80a5ff1769cb1227": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ebbd1059e3d4b41acb2d2373b19a7af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b17feab9bc69468495776a737ca575d1",
              "IPY_MODEL_5462b1b99710466cb59d132612bfc872",
              "IPY_MODEL_d87317fc29a04516a25897f7d483c468"
            ],
            "layout": "IPY_MODEL_5785961c657f44439f6f0b2f54d6a764"
          }
        },
        "70802b1b23e44fd19edee464ee5e4a70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e679f738070a46b0835bc33751a58490",
            "placeholder": "​",
            "style": "IPY_MODEL_c29f91353718421487bb4892ed31dec8",
            "value": " 2000/2000 [00:03&lt;00:00, 565.50 examples/s]"
          }
        },
        "7655f7fba5794b33a4834c84284d8b2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0cb958921da456a9374308203ad5f03",
              "IPY_MODEL_140a8c34733f4f9cb104cc41d2c5c501",
              "IPY_MODEL_c64a291ffd43491aa45ee71c28dd1010"
            ],
            "layout": "IPY_MODEL_af95ba59189545059660df0d8769a30b"
          }
        },
        "8c99e5ff4b984a7cb395914981456a33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0cb958921da456a9374308203ad5f03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5aef22247eb94edd80a5ff1769cb1227",
            "placeholder": "​",
            "style": "IPY_MODEL_16622acd3b454aea981cebbf76d4f63d",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "a2d43ead7656449ab6617ab4003e94a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af95ba59189545059660df0d8769a30b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b17feab9bc69468495776a737ca575d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd5daf7e31474087a95c70ba33b5a40d",
            "placeholder": "​",
            "style": "IPY_MODEL_8c99e5ff4b984a7cb395914981456a33",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "ba58d631ff8c46b792caa722482c5168": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d63f111548245f8a697c7b12a22c232",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a28c3dff0b74e849c1a618f7c2d0a46",
            "value": 2000
          }
        },
        "bae11f85f2634fda93cee420996bc332": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37cab3be5f1843998d798536c60afecd",
            "placeholder": "​",
            "style": "IPY_MODEL_49f18819f72d40268967d44716c2b354",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "bd5daf7e31474087a95c70ba33b5a40d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c29f91353718421487bb4892ed31dec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c64a291ffd43491aa45ee71c28dd1010": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2d43ead7656449ab6617ab4003e94a0",
            "placeholder": "​",
            "style": "IPY_MODEL_2df6358818d5472598f30e6e2dd3deee",
            "value": " 2000/2000 [00:03&lt;00:00, 857.43 examples/s]"
          }
        },
        "d87317fc29a04516a25897f7d483c468": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ee57a6eaf3f4debaeb44f917df321bb",
            "placeholder": "​",
            "style": "IPY_MODEL_3eb4b66a5b324973a64ea2a57aef6a33",
            "value": " 35000/35000 [01:04&lt;00:00, 604.12 examples/s]"
          }
        },
        "db996a4601c248f9a103b3d0756cda78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc5de4a1303b4e29a6c37628b4841a7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e679f738070a46b0835bc33751a58490": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91b257cc402f409986a4da14bfc29e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6aec96102628434e8337936e8644db70",
              "IPY_MODEL_f33d6e804b564c33badce2c8d89423ac",
              "IPY_MODEL_f4ceca315899424f990a397f8ca36e39"
            ],
            "layout": "IPY_MODEL_8e9c778d3c6a4fec9879cb03920bbd75"
          }
        },
        "6aec96102628434e8337936e8644db70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dcd30ce5abb45e282f8374f77510dd3",
            "placeholder": "​",
            "style": "IPY_MODEL_70420f2c87404e4d8c51de7874e23b94",
            "value": "Downloading builder script: 100%"
          }
        },
        "f33d6e804b564c33badce2c8d89423ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d51dca933b2346399d6ecfc17bfc74a9",
            "max": 6270,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79b53f06c3e043adaf1846b6bac116ee",
            "value": 6270
          }
        },
        "f4ceca315899424f990a397f8ca36e39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b630e617b4344f69e65503baa9fe328",
            "placeholder": "​",
            "style": "IPY_MODEL_7824ef33018c41528a44bd945fbf66ff",
            "value": " 6.27k/6.27k [00:00&lt;00:00, 443kB/s]"
          }
        },
        "8e9c778d3c6a4fec9879cb03920bbd75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dcd30ce5abb45e282f8374f77510dd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70420f2c87404e4d8c51de7874e23b94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d51dca933b2346399d6ecfc17bfc74a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79b53f06c3e043adaf1846b6bac116ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b630e617b4344f69e65503baa9fe328": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7824ef33018c41528a44bd945fbf66ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26e48407188441d8949ee498ce5c62f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_805d42b7630f491b867cc0912ebdef88",
              "IPY_MODEL_96f2294f03264a27a5cb53e4b5c07456",
              "IPY_MODEL_5931550b9602490297504aa8a7e4acdc"
            ],
            "layout": "IPY_MODEL_976895ca7c6b46f3a59046834b02843a"
          }
        },
        "805d42b7630f491b867cc0912ebdef88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4338cadfff914a82beef8cbd09c87e38",
            "placeholder": "​",
            "style": "IPY_MODEL_b67de56ff70948c0a392fae76864023a",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "96f2294f03264a27a5cb53e4b5c07456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_022166a0835d41698b603190fdc8278c",
            "max": 35000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3980e98eb9c8469b97834110bec08caa",
            "value": 35000
          }
        },
        "5931550b9602490297504aa8a7e4acdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a92d7ec8cddd40c996f5ea535697f189",
            "placeholder": "​",
            "style": "IPY_MODEL_6329a4a3fc1e468db51c1b3c0954f26b",
            "value": " 35000/35000 [00:55&lt;00:00, 736.36 examples/s]"
          }
        },
        "976895ca7c6b46f3a59046834b02843a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4338cadfff914a82beef8cbd09c87e38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b67de56ff70948c0a392fae76864023a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "022166a0835d41698b603190fdc8278c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3980e98eb9c8469b97834110bec08caa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a92d7ec8cddd40c996f5ea535697f189": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6329a4a3fc1e468db51c1b3c0954f26b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f73116f8599149f8bd1da4ed771a83bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4330435f245041878691b5943db20871",
              "IPY_MODEL_90071ca104694ddfafa86c56e14ec4b2",
              "IPY_MODEL_6562e966c9a845f2b2f9e183cd59a6c1"
            ],
            "layout": "IPY_MODEL_87a7ee82377047ea8ab5eb391fa94a07"
          }
        },
        "4330435f245041878691b5943db20871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eea59f99414547f38060d9939cfa3f58",
            "placeholder": "​",
            "style": "IPY_MODEL_5fdcb29d372d40c8aa3873ebe2a33e52",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "90071ca104694ddfafa86c56e14ec4b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f551b657780246179f176e4b0e827602",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_059ad1ebb1cb469882dc27b1c829aa6e",
            "value": 2000
          }
        },
        "6562e966c9a845f2b2f9e183cd59a6c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d07bba41e7514715b80a539382b2fc04",
            "placeholder": "​",
            "style": "IPY_MODEL_691afa7a69094f9899c901b5492f8f30",
            "value": " 2000/2000 [00:02&lt;00:00, 675.51 examples/s]"
          }
        },
        "87a7ee82377047ea8ab5eb391fa94a07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eea59f99414547f38060d9939cfa3f58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fdcb29d372d40c8aa3873ebe2a33e52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f551b657780246179f176e4b0e827602": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "059ad1ebb1cb469882dc27b1c829aa6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d07bba41e7514715b80a539382b2fc04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "691afa7a69094f9899c901b5492f8f30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7adf02e6cba4869b732971161baf043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7245ef7cabcf4b35bfabd32df4092936",
              "IPY_MODEL_4517b6ecf6d347a4a201d57ae567ed7a",
              "IPY_MODEL_5d9fc12f767f408696e5244fc84c587d"
            ],
            "layout": "IPY_MODEL_5544413bb07f499e810c31a8b28298b5"
          }
        },
        "7245ef7cabcf4b35bfabd32df4092936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59403dd61140474b98b09ca21551387b",
            "placeholder": "​",
            "style": "IPY_MODEL_8855b5c10f16479a8d4c4be31f0ad502",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "4517b6ecf6d347a4a201d57ae567ed7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a32d06725b64ad29328e84abe364711",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b33498653c594348ac5034e8cf55365c",
            "value": 2000
          }
        },
        "5d9fc12f767f408696e5244fc84c587d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_732bbd6c9f78414b99e11cae1ed0c487",
            "placeholder": "​",
            "style": "IPY_MODEL_906e0e1033bd43bc8d7dbef4f2291e16",
            "value": " 2000/2000 [00:02&lt;00:00, 675.62 examples/s]"
          }
        },
        "5544413bb07f499e810c31a8b28298b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59403dd61140474b98b09ca21551387b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8855b5c10f16479a8d4c4be31f0ad502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a32d06725b64ad29328e84abe364711": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b33498653c594348ac5034e8cf55365c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "732bbd6c9f78414b99e11cae1ed0c487": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "906e0e1033bd43bc8d7dbef4f2291e16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}